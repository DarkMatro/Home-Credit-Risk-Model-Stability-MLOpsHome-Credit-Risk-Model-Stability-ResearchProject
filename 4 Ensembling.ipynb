{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cbcccde-178b-4ae6-b789-a37caf1bc121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from copy import deepcopy\n",
    "\n",
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from dataset import Dataset\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from metrics import gini_stability, metrics_estimation\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.calibration import CalibratedClassifierCV, CalibrationDisplay\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedGroupKFold,\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier, early_stopping, Dataset as lgb_Dataset\n",
    "\n",
    "RAND = 0\n",
    "N_FOLDS = 5\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a938d3e4-7dc9-43b8-bc80-d9e6d03643b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pl.read_parquet(\"dataframe.parquet\")\n",
    "X = df_train.to_pandas()\n",
    "X.set_index(\"case_id\", inplace=True)\n",
    "del df_train\n",
    "weeks = X.pop(\"WEEK_NUM\")\n",
    "y = X.pop(\"target\")\n",
    "cat_features = X.select_dtypes(exclude=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597aee68-b7b0-4bfc-9690-56e77dbe0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_cat = SimpleImputer(missing_values=None, strategy=\"constant\", fill_value=\"None\")\n",
    "X[cat_features] = imputer_cat.fit_transform(X[cat_features], y)\n",
    "X[cat_features] = X[cat_features].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "257cfbdf-04f3-4943-9a1c-74bd323f31b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, weeks_train, weeks_test = train_test_split(\n",
    "    X, y, weeks, test_size=0.2, stratify=y, shuffle=True, random_state=RAND\n",
    ")\n",
    "\n",
    "X_train_, X_val, y_train_, y_val, weeks_train_, weeks_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    weeks_train,\n",
    "    test_size=0.16,\n",
    "    stratify=y_train,\n",
    "    shuffle=True,\n",
    "    random_state=RAND,\n",
    ")\n",
    "scale_pos_weight = float(np.sum(y_train_ == 0)) / np.sum(y_train_ == 1)\n",
    "eval_set = [(X_val, y_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4932647f-e7be-40a4-909d-3afc0a4436fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {}\n",
    "for study_name in [\"cat_boost3\", \"lgbm21\", \"xgb12\"]:\n",
    "    study = optuna.load_study(\n",
    "        storage=\"sqlite:///{}.db\".format(study_name),\n",
    "        study_name=study_name,\n",
    "    )\n",
    "    key = \"\".join([i for i in study_name if not i.isdigit()])\n",
    "    best_params[key] = study.best_params\n",
    "best_params[\"xgb\"][\"n_estimators\"] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a6fdb7-30c5-4a2a-a60f-23516b704cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"cat_boost\": {\n",
    "        \"eval_metric\": \"CrossEntropy\",\n",
    "        \"cat_features\": cat_features,\n",
    "        \"boosting_type\": \"Plain\",\n",
    "        \"border_count\": 32,\n",
    "        \"od_wait\": 20,\n",
    "        \"task_type\": \"GPU\",\n",
    "    },\n",
    "    \"lgbm\": {\"n_jobs\": 24, \"verbose\": -1},\n",
    "    \"xgb\": {\"enable_categorical\": True, \"device\": \"cuda\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb464b78-11d6-44c4-8e87-cbfb91044157",
   "metadata": {},
   "source": [
    "Составим ансамблевые модели для улучшения результатов по сравнению с базовыми моделями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498ec01c-199e-4fab-87e8-570ebd2e75f1",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e36edc-9022-4599-afc4-b2d9bef50c1f",
   "metadata": {},
   "source": [
    "Заранее обучим классификаторы на лучших параметрах и используем CalibratedClassifierCV с cv=\"prefit\" для калибровки на валидационных данных. Для этого напишем свой класс реализующий VotingClassifier использующий предобученные классификаторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fcebd03-aa86-4807-b23a-85f55b93a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_catboost = CatBoostClassifier(\n",
    "    random_state=RAND,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    **params[\"cat_boost\"],\n",
    "    **best_params[\"cat_boost\"]\n",
    ")\n",
    "tuned_catboost.fit(\n",
    "    X_train_, y_train_, eval_set=eval_set, early_stopping_rounds=100, verbose=0\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ad96cef-55f2-4de3-81dd-8a8dad14bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_lgb = LGBMClassifier(\n",
    "    random_state=RAND,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    **params[\"lgbm\"],\n",
    "    **best_params[\"lgbm\"]\n",
    ")\n",
    "tuned_lgb.fit(\n",
    "    X_train_,\n",
    "    y_train_,\n",
    "    eval_set=eval_set,\n",
    "    eval_metric=\"auc\",\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=100, verbose=0),\n",
    "    ],\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7c7ae1e-96b5-4698-8d36-026ffc122b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_xgb = XGBClassifier(\n",
    "    random_state=RAND,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    early_stopping_rounds=100,\n",
    "    eval_metric=\"auc\",\n",
    "    **params[\"xgb\"],\n",
    "    **best_params[\"xgb\"]\n",
    ")\n",
    "tuned_xgb.fit(X_train_, y_train_, eval_set=eval_set, verbose=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "faad6c7b-0343-4dc2-b49f-0594d7e8399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tuned_catboost.bin\", \"wb\") as fout:\n",
    "    dill.dump(tuned_catboost, fout)\n",
    "with open(\"tuned_lgb.bin\", \"wb\") as fout:\n",
    "    dill.dump(tuned_lgb, fout)\n",
    "with open(\"tuned_xgb.bin\", \"wb\") as fout:\n",
    "    dill.dump(tuned_xgb, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dda5ec0-c8f6-43b3-8a0e-e46274a04a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_catboost = CatBoostClassifier(\n",
    "    random_state=RAND, scale_pos_weight=scale_pos_weight, **params[\"cat_boost\"]\n",
    ")\n",
    "baseline_catboost.fit(\n",
    "    X_train_, y_train_, eval_set=eval_set, early_stopping_rounds=100, verbose=0\n",
    ")\n",
    "with open(\"baseline_catboost.bin\", \"wb\") as fout:\n",
    "    dill.dump(baseline_catboost, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c6ca0874-2884-4cf2-a83b-8f616117f110",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class VotingClassifierCustom(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Soft Voting classifier for prefitted estimators.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models: list of CalibratedClassifierCV estimators with prefitted estimators\n",
    "    weights: array-like of shape (n_classifiers,), default=None\n",
    "        Sequence of weights (`float` or `int`) to weight the occurrences of\n",
    "        class probabilities before averaging. Uses no weights if `None`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, models: list[tuple], weights=None) -> None:\n",
    "        for model in models:\n",
    "            assert isinstance(\n",
    "                model, CalibratedClassifierCV\n",
    "            ), \"All models must be instance of CalibratedClassifierCV with prefitted estimators\"\n",
    "        if weights is not None:\n",
    "            assert len(weights) == len(\n",
    "                models\n",
    "            ), \"Shape of weights must be equal to number of models.\"\n",
    "        self.models = models\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X: pd.DataFrame | np.ndarray, y: pd.Series | np.ndarray) -> object:\n",
    "        \"\"\"Fit the estimators.\n",
    "        Already fitted classifiers will be calibrated via the parameter cv=\"prefit\".\n",
    "        In this case, no cross-validation is used and all provided data is used for calibration.\n",
    "        The user has to take care manually that data for model fitting and calibration are disjoint.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        y: array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns the instance itself.\n",
    "        \"\"\"\n",
    "        for model in self.models:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def find_weights(\n",
    "        self,\n",
    "        X: pd.DataFrame | np.ndarray,\n",
    "        y: pd.Series | np.ndarray,\n",
    "        weeks: pd.Series | np.ndarray,\n",
    "        method: str = \"Powell\",\n",
    "    ) -> None:\n",
    "        \"\"\"Find best weights using scipy.minimize\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "\n",
    "        weeks : array-like of shape (n_samples,)\n",
    "            groupping feature\n",
    "\n",
    "        method: str, optional\n",
    "            Type of solver. Should be one of ‘Nelder-Mead’, ‘Powell’, ‘CG’, ‘BFGS’, ‘L-BFGS-B’,\n",
    "            ‘TNC’, ‘COBYLA’, ‘SLSQP’, ‘trust-constr’\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        pred_cols = [f\"pred_{i}\" for i in range(len(self.models))]\n",
    "        bounds = [(0, 1)] * len(pred_cols)\n",
    "        df = self.base_df(X, y, weeks, pred_cols)\n",
    "        gini_score_fn = gini_wrapper(df)\n",
    "        w_searcher = WeightsSearcher(gini_score_fn, bounds, method=method)\n",
    "        optimized_weights = w_searcher.find_weights(df[pred_cols].to_numpy(), y)\n",
    "        self.weights = optimized_weights\n",
    "        return\n",
    "\n",
    "    def base_df(\n",
    "        self,\n",
    "        X: pd.DataFrame | np.ndarray,\n",
    "        y: pd.Series | np.ndarray,\n",
    "        weeks: pd.Series | np.ndarray,\n",
    "        pred_cols: list,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Prepare dataframe with predicted scores for weights optimizing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "\n",
    "        weeks : array-like of shape (n_samples,)\n",
    "            groupping feature\n",
    "\n",
    "        pred_cols: list\n",
    "            names of columns\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df : pd.DataFrame\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame()\n",
    "        for name, model in zip(pred_cols, self.models):\n",
    "            y_scores = pd.Series(model.predict_proba(X)[:, 1], name=name)\n",
    "            df = pd.concat([df, y_scores], axis=1)\n",
    "        df.set_index(X.index, inplace=True)\n",
    "        df = pd.concat([df, weeks, y], axis=1)\n",
    "        return df\n",
    "\n",
    "    def predict(self, X: pd.DataFrame | np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predict class labels for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : array-like of shape (n_samples,)\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        y_scores = self.predict_proba(X)\n",
    "        y_pred = np.argmax(y_scores, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def predict_proba(self, X: pd.DataFrame | np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute probabilities of possible outcomes for samples in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_scores : array-like of shape (n_samples, n_classes)\n",
    "            Weighted probability for each class per sample.\n",
    "        \"\"\"\n",
    "        y_scores = []\n",
    "        for i, model in enumerate(self.models):\n",
    "            prob = model.predict_proba(X)\n",
    "            scores = prob if self.weights is None else self.weights[i] * prob\n",
    "            y_scores.append(scores)\n",
    "        y_scores = np.sum(y_scores, axis=0)\n",
    "        return y_scores\n",
    "\n",
    "\n",
    "def gini_wrapper(base_df: pd.DataFrame) -> callable:\n",
    "    \"\"\"Define loss_fn for minimize\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_df: pd.DataFrame\n",
    "        with predicted scores, weeks and target\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : callable\n",
    "    \"\"\"\n",
    "    base_df = base_df[[\"WEEK_NUM\", \"target\"]].copy()\n",
    "\n",
    "    def gini_wrapper_inner(target: np.ndarray, scores: np.ndarray) -> float:\n",
    "        base_df[\"score\"] = scores\n",
    "        gini_score = gini_stability(base_df)\n",
    "        return 1 - gini_score\n",
    "\n",
    "    return gini_wrapper_inner\n",
    "\n",
    "\n",
    "class WeightsSearcher:\n",
    "    \"\"\"Find best weights\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    loss_fn: callable:\n",
    "        loss function\n",
    "\n",
    "    bounds: list:\n",
    "        like [(0, 1), (0, 1), (0, 1)]\n",
    "\n",
    "    mode : str\n",
    "\n",
    "    method : str, optional\n",
    "        Type of solver. Should be one of ‘Nelder-Mead’, ‘Powell’, ‘CG’, ‘BFGS’, ‘L-BFGS-B’,\n",
    "        ‘TNC’, ‘COBYLA’, ‘SLSQP’, ‘trust-constr’\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loss_fn, bounds=[], mode: str = \"min\", method: str = \"SLSQP\"):\n",
    "        self.loss_fn = loss_fn\n",
    "        self.bounds = bounds\n",
    "        self.mode = mode\n",
    "        self.method = method\n",
    "\n",
    "    def _objective_function_wrapper(\n",
    "        self, y_pred: np.ndarray, y_true: np.ndarray, obj_fn: callable\n",
    "    ) -> callable:\n",
    "        \"\"\"Objective function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred: np.ndarray\n",
    "\n",
    "        y_true: np.ndarray\n",
    "\n",
    "        obj_fn: callable\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : callable\n",
    "        \"\"\"\n",
    "\n",
    "        def objective_function(weights: np.ndarray) -> float:\n",
    "            pred_weighted = (y_pred * weights).sum(axis=1)\n",
    "            score = obj_fn(y_true, pred_weighted)\n",
    "            return score\n",
    "\n",
    "        return objective_function\n",
    "\n",
    "    def find_weights(self, val_preds: np.ndarray, y_true: np.ndarray) -> list:\n",
    "        \"\"\"Objective function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred: np.ndarray\n",
    "\n",
    "        y_true: np.ndarray\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        optimized_weights : list\n",
    "        \"\"\"\n",
    "        len_models = len(self.bounds)\n",
    "        bounds = [0, 1] * len_models if len(self.bounds) == 0 else self.bounds\n",
    "        initial_weights = np.ones(len_models) / len_models\n",
    "        objective_function = self._objective_function_wrapper(\n",
    "            val_preds, y_true, self.loss_fn\n",
    "        )\n",
    "        result = minimize(\n",
    "            objective_function,\n",
    "            initial_weights,\n",
    "            bounds=bounds,\n",
    "            method=self.method,\n",
    "        )\n",
    "        optimized_weights = result.x\n",
    "        optimized_weights /= np.sum(optimized_weights)\n",
    "        return optimized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3b4adc75-8e07-4efb-aec3-8ba75eb2e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "clb_cat = CalibratedClassifierCV(tuned_catboost, method=\"isotonic\", cv=\"prefit\")\n",
    "clb_lgb = CalibratedClassifierCV(tuned_lgb, method=\"isotonic\", cv=\"prefit\")\n",
    "clb_xgb = CalibratedClassifierCV(tuned_xgb, method=\"isotonic\", cv=\"prefit\")\n",
    "models = [clb_cat, clb_lgb, clb_xgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9ffb3490-7655-4351-a5c9-1b05103ccc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_clf_w_auto = VotingClassifierCustom(models)\n",
    "vt_clf_w_auto.fit(X_val, y_val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8c025c09-26b5-4cf1-a00d-cd3e18068152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61501642, 0.10484445, 0.28013913])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt_clf_w_auto.find_weights(X_val, y_val, weeks_val, method=\"Powell\")\n",
    "vt_clf_w_auto.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "64b08e03-0e23-47ff-9b2b-a48fdce7901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metrics_estimation(\n",
    "    vt_clf_w,\n",
    "    X_train_,\n",
    "    y_train_,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    weeks_train_,\n",
    "    weeks_test,\n",
    "    name=\"Voting_weighted_auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03cb6e-6693-491d-a632-907feba7786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [1.0, 0.1, 1.0]\n",
    "vt_clf_w = VotingClassifierCustom(models, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea04ec9-d68f-4d2a-93ce-cb2a0a624579",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_clf_w.fit(X_val, y_val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42c07f11-1bc8-4b31-a734-9d1a6cb8ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_ = metrics_estimation(\n",
    "    vt_clf_w,\n",
    "    X_train_,\n",
    "    y_train_,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    weeks_train_,\n",
    "    weeks_test,\n",
    "    name=\"Voting_weighted\",\n",
    ")\n",
    "metrics = pd.concat([metrics, metrics_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38d74e13-5633-49e4-a98a-2da2af101cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_clf = VotingClassifierCustom(models)\n",
    "vt_clf.fit(X_val, y_val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77714ddd-63dd-4b30-9f97-0d8b3434a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_ = metrics_estimation(\n",
    "    vt_clf,\n",
    "    X_train_,\n",
    "    y_train_,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    weeks_train_,\n",
    "    weeks_test,\n",
    "    name=\"Voting_no_weights\",\n",
    ")\n",
    "metrics = pd.concat([metrics, metrics_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9baaa291-4dc8-4378-97ec-cc0a30455a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>gini_stability</th>\n",
       "      <th>overfitting, %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_train</th>\n",
       "      <td>0.968692</td>\n",
       "      <td>0.894470</td>\n",
       "      <td>0.618962</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.102074</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_test</th>\n",
       "      <td>0.968575</td>\n",
       "      <td>0.857126</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.014988</td>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.688272</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_train</th>\n",
       "      <td>0.968697</td>\n",
       "      <td>0.893210</td>\n",
       "      <td>0.606811</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.109814</td>\n",
       "      <td>0.770778</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_test</th>\n",
       "      <td>0.968542</td>\n",
       "      <td>0.857288</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>0.116794</td>\n",
       "      <td>0.689036</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_train</th>\n",
       "      <td>0.968654</td>\n",
       "      <td>0.902040</td>\n",
       "      <td>0.649682</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.012528</td>\n",
       "      <td>0.120357</td>\n",
       "      <td>0.790379</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_test</th>\n",
       "      <td>0.968588</td>\n",
       "      <td>0.855851</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.128851</td>\n",
       "      <td>0.684912</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy   ROC_AUC  Precision    Recall        f1  \\\n",
       "model                                                                           \n",
       "Voting_weighted_auto_train  0.968692  0.894470   0.618962  0.010728  0.021090   \n",
       "Voting_weighted_auto_test   0.968575  0.857126   0.514085  0.007605  0.014988   \n",
       "Voting_weighted_train       0.968697  0.893210   0.606811  0.012154  0.023831   \n",
       "Voting_weighted_test        0.968542  0.857288   0.482558  0.008647  0.016989   \n",
       "Voting_no_weights_train     0.968654  0.902040   0.649682  0.006325  0.012528   \n",
       "Voting_no_weights_test      0.968588  0.855851   0.550000  0.004584  0.009092   \n",
       "\n",
       "                             Logloss  gini_stability  overfitting, %  \n",
       "model                                                                 \n",
       "Voting_weighted_auto_train  0.102074        0.773653        4.356915  \n",
       "Voting_weighted_auto_test   0.110082        0.688272        4.356915  \n",
       "Voting_weighted_train       0.109814        0.770778        4.190239  \n",
       "Voting_weighted_test        0.116794        0.689036        4.190239  \n",
       "Voting_no_weights_train     0.120357        0.790379        5.396866  \n",
       "Voting_no_weights_test      0.128851        0.684912        5.396866  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a350dfb-d130-4a68-aea8-8fe598a4a0be",
   "metadata": {},
   "source": [
    "Voting c весами показывает результаты чуть лучше чем без весов. Автоматический поиск весов не оказался лучше ручного выбора. Трудность в том, что эти веса еще нужно подобрать не увеличив переобучение. По сравнению со значением gini_stability=0.689616\tдля одного CatBoost с лучшими гиперпараметрами, Voting не позволяет получить результаты лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3f289-43fc-4975-97b5-9dc2920cadc5",
   "metadata": {},
   "source": [
    "# Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc6a8208-000a-49ea-b946-b465431c8729",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class BlendingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Blending Ensemble classifier of multiple estimators and meta estimator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimators : list\n",
    "        Base estimators which will be stacked together.\n",
    "        The type of estimator is generally expected to be a classifier.\n",
    "    final_estimator : estimator, default=None\n",
    "        A classifier which will be used to combine the base estimators.\n",
    "        The default classifier is a LogisticRegression.\n",
    "    stack_method : {'predict_proba', 'predict'}, default='predict_proba'\n",
    "        Methods called for each base estimator. It can be:\n",
    "        'predict_proba'  or 'predict'\n",
    "    n_jobs : int, default=-1\n",
    "        The number of jobs to run in parallel all `estimators` `fit`.\n",
    "         -1 means using all processors.\n",
    "         None means use number of base estimators\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimators: list,\n",
    "        final_estimator=None,\n",
    "        stack_method: str = \"predict_proba\",\n",
    "        n_jobs: int | None = None,\n",
    "    ):\n",
    "        assert len(estimators) > 1, \"More than 1 estimators must be passed.\"\n",
    "        self.estimators = estimators\n",
    "        self.__estimators_train = None\n",
    "        self.__estimators_val = None\n",
    "        self.final_estimator = (\n",
    "            LogisticRegression(class_weight=\"balanced\", n_jobs=-1)\n",
    "            if final_estimator is None\n",
    "            else final_estimator\n",
    "        )\n",
    "        self.n_jobs = len(estimators) if n_jobs is None else n_jobs\n",
    "        self.stack_method = stack_method\n",
    "\n",
    "    def __sklearn_is_fitted__(self) -> bool:\n",
    "        \"\"\"Perform is_fitted validation for final estimator.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: bool\n",
    "        \"\"\"\n",
    "        return check_is_fitted(self.final_estimator)\n",
    "\n",
    "    def _fit_base_estimators(\n",
    "        self,\n",
    "        X: pd.DataFrame | np.ndarray,\n",
    "        y: pd.Series | np.ndarray,\n",
    "        on_train: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"Fit base estimators.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "\n",
    "        on_train : bool, default=True\n",
    "            fit __estimators_train on train data if True\n",
    "            or __estimators_val on validation data if False\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        fitted_estimators = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(est.fit)(X, y) for est in deepcopy(self.estimators)\n",
    "        )\n",
    "        if on_train:\n",
    "            self.__estimators_train = fitted_estimators\n",
    "        else:\n",
    "            self.__estimators_val = fitted_estimators\n",
    "        return\n",
    "\n",
    "    def _meta_X(\n",
    "        self, X: pd.DataFrame | np.ndarray, on_train: bool = True\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Generate meta data using fitted base estimators\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        on_train : bool, default=True\n",
    "            predict using self.__estimators_train if True\n",
    "            or self.__estimators_val if False\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        meta_X : pd.DataFrame\n",
    "            Meta data for meta estimator\n",
    "        \"\"\"\n",
    "        estimators = self.__estimators_train if on_train else self.__estimators_val\n",
    "        assert self.stack_method in [\n",
    "            \"predict_proba\",\n",
    "            \"predict\",\n",
    "        ], \"stack_method not passed\"\n",
    "        if self.stack_method == \"predict_proba\":\n",
    "            X_pred = (delayed(self.proba)(est, X) for est in estimators)\n",
    "        elif self.stack_method == \"predict\":\n",
    "            X_pred = (delayed(est.predict)(X) for est in estimators)\n",
    "        X_pred = Parallel(n_jobs=self.n_jobs)(X_pred)\n",
    "        meta_X = pd.DataFrame(X_pred).T\n",
    "        return meta_X\n",
    "\n",
    "    def _meta_data_train(\n",
    "        self,\n",
    "        X: pd.DataFrame | np.ndarray,\n",
    "        y: pd.Series | np.ndarray,\n",
    "        test_size: float = 0.15,\n",
    "        random_state: int = 0,\n",
    "    ) -> tuple:\n",
    "        \"\"\"\n",
    "        Get meta data for train.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        y: array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "\n",
    "        test_size: float, default=0.15\n",
    "            For train_test_split.\n",
    "\n",
    "        random_state: int, default=0\n",
    "            For train_test_split.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : tuple of meta_X, meta_y\n",
    "            Meta data\n",
    "        \"\"\"\n",
    "        X_train_, X_val, y_train_, y_val = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            stratify=y,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        self._fit_base_estimators(X_train_, y_train_, on_train=True)\n",
    "        self._fit_base_estimators(X_val, y_val, on_train=False)\n",
    "        meta_X_train = self._meta_X(X_val, on_train=True)\n",
    "        meta_X_val = self._meta_X(X_train_, on_train=False)\n",
    "        meta_X = pd.concat([meta_X_train, meta_X_val])\n",
    "        meta_y = np.concatenate((y_val, y_train_))\n",
    "        return meta_X, meta_y\n",
    "\n",
    "    def _meta_data_test(self, X: pd.DataFrame | np.ndarray) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get meta data for predict.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        meta_X : pd.DataFrame\n",
    "            Meta data\n",
    "        \"\"\"\n",
    "        meta_X_train = self._meta_X(X, on_train=True)\n",
    "        meta_X_val = self._meta_X(X, on_train=False)\n",
    "        meta_X = pd.concat([meta_X_train, meta_X_val])\n",
    "        return meta_X\n",
    "\n",
    "    def fit(self, X: pd.DataFrame | np.ndarray, y: pd.Series | np.ndarray, **kwargs):\n",
    "        \"\"\"Fit the final_estimator on meta data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        y: array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns the instance itself.\n",
    "        \"\"\"\n",
    "        meta_X_final, meta_y_final = self._meta_data_train(X, y, **kwargs)\n",
    "        self.final_estimator.fit(meta_X_final, meta_y_final)\n",
    "        self.classes_ = self.final_estimator.classes_\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: pd.DataFrame | np.ndarray) -> np.array:\n",
    "        \"\"\"Predict class labels for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : array-like of shape (n_samples,)\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        meta_X = self._meta_data_test(X)\n",
    "        y_score = self.predict_proba(X)\n",
    "        y_pred = np.argmax(y_score, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def predict_proba(self, X: pd.DataFrame | np.ndarray) -> np.array:\n",
    "        \"\"\"Compute probabilities of possible outcomes for samples in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_scores : array-like of shape (n_samples, n_classes)\n",
    "            Weighted probability for each class per sample.\n",
    "        \"\"\"\n",
    "        meta_X = self._meta_data_test(X)\n",
    "        y_scores = self.final_estimator.predict_proba(meta_X)\n",
    "        idx = y_scores.shape[0] // 2\n",
    "        y_scores = (y_scores[:idx] + y_scores[idx:]) / 2.0\n",
    "        return y_scores\n",
    "\n",
    "    @staticmethod\n",
    "    def proba(estimator: BaseEstimator, X: pd.DataFrame | np.ndarray) -> np.ndarray:\n",
    "        \"\"\"predict_proba and return column 1\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        estimator: BaseEstimator\n",
    "\n",
    "        X : {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_scores : array-like of shape (n_samples, n_classes)\n",
    "            Weighted probability for each class per sample.\n",
    "        \"\"\"\n",
    "        y_scores = estimator.predict_proba(X)[:, 1]\n",
    "        return y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c77e6d1-72fd-4976-826b-f42f4f8ef68b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_clf(rnd_state: int) -> BlendingClassifier:\n",
    "    \"\"\"Returns BlendingClassifier with estimators as tuned CatBoostClassifier,\n",
    "    LGBMClassifier, XGBClassifier with random_state = rnd_state\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rnd_state : int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    clf : BlendingClassifier\n",
    "    \"\"\"\n",
    "    clf_catboost = CatBoostClassifier(\n",
    "        random_state=rnd_state,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        verbose=0,\n",
    "        **params[\"cat_boost\"],\n",
    "        **best_params[\"cat_boost\"]\n",
    "    )\n",
    "    clf_lgb = LGBMClassifier(\n",
    "        random_state=rnd_state,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        **params[\"lgbm\"],\n",
    "        **best_params[\"lgbm\"]\n",
    "    )\n",
    "    clf_xgb = XGBClassifier(\n",
    "        random_state=rnd_state,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        eval_metric=\"auc\",\n",
    "        verbose=0,\n",
    "        **params[\"xgb\"],\n",
    "        **best_params[\"xgb\"]\n",
    "    )\n",
    "    estimators = [clf_catboost, clf_lgb, clf_xgb]\n",
    "    final_estimator = LogisticRegression(\n",
    "        class_weight=\"balanced\", random_state=rnd_state, n_jobs=24\n",
    "    )\n",
    "    clf = BlendingClassifier(estimators, final_estimator, n_jobs=1)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddf22e39-4234-45c7-9b40-b7fa716e1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "blending_clf = get_clf(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a16dc-80c1-42be-9b43-78056ba6eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "blending_clf.fit(X_train, y_train, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6e842db-8046-4318-9906-00f63d535fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_ = metrics_estimation(\n",
    "    blending_clf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    weeks_train,\n",
    "    weeks_test,\n",
    "    name=\"Blending\",\n",
    ")\n",
    "metrics = pd.concat([metrics, metrics_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a5618775-2fe2-4cea-9616-c169ff7ff575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>gini_stability</th>\n",
       "      <th>overfitting, %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_train</th>\n",
       "      <td>0.968692</td>\n",
       "      <td>0.894470</td>\n",
       "      <td>0.618962</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.102074</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_test</th>\n",
       "      <td>0.968575</td>\n",
       "      <td>0.857126</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.014988</td>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.688272</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_train</th>\n",
       "      <td>0.968697</td>\n",
       "      <td>0.893210</td>\n",
       "      <td>0.606811</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.109814</td>\n",
       "      <td>0.770778</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_test</th>\n",
       "      <td>0.968542</td>\n",
       "      <td>0.857288</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>0.116794</td>\n",
       "      <td>0.689036</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_train</th>\n",
       "      <td>0.968654</td>\n",
       "      <td>0.902040</td>\n",
       "      <td>0.649682</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.012528</td>\n",
       "      <td>0.120357</td>\n",
       "      <td>0.790379</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_test</th>\n",
       "      <td>0.968588</td>\n",
       "      <td>0.855851</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.128851</td>\n",
       "      <td>0.684912</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_train</th>\n",
       "      <td>0.772604</td>\n",
       "      <td>0.890391</td>\n",
       "      <td>0.107409</td>\n",
       "      <td>0.852689</td>\n",
       "      <td>0.190785</td>\n",
       "      <td>0.475913</td>\n",
       "      <td>0.766394</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_test</th>\n",
       "      <td>0.769366</td>\n",
       "      <td>0.856921</td>\n",
       "      <td>0.098917</td>\n",
       "      <td>0.781331</td>\n",
       "      <td>0.175603</td>\n",
       "      <td>0.481936</td>\n",
       "      <td>0.686508</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy   ROC_AUC  Precision    Recall        f1  \\\n",
       "model                                                                           \n",
       "Voting_weighted_auto_train  0.968692  0.894470   0.618962  0.010728  0.021090   \n",
       "Voting_weighted_auto_test   0.968575  0.857126   0.514085  0.007605  0.014988   \n",
       "Voting_weighted_train       0.968697  0.893210   0.606811  0.012154  0.023831   \n",
       "Voting_weighted_test        0.968542  0.857288   0.482558  0.008647  0.016989   \n",
       "Voting_no_weights_train     0.968654  0.902040   0.649682  0.006325  0.012528   \n",
       "Voting_no_weights_test      0.968588  0.855851   0.550000  0.004584  0.009092   \n",
       "Blending_train              0.772604  0.890391   0.107409  0.852689  0.190785   \n",
       "Blending_test               0.769366  0.856921   0.098917  0.781331  0.175603   \n",
       "\n",
       "                             Logloss  gini_stability  overfitting, %  \n",
       "model                                                                 \n",
       "Voting_weighted_auto_train  0.102074        0.773653        4.356915  \n",
       "Voting_weighted_auto_test   0.110082        0.688272        4.356915  \n",
       "Voting_weighted_train       0.109814        0.770778        4.190239  \n",
       "Voting_weighted_test        0.116794        0.689036        4.190239  \n",
       "Voting_no_weights_train     0.120357        0.790379        5.396866  \n",
       "Voting_no_weights_test      0.128851        0.684912        5.396866  \n",
       "Blending_train              0.475913        0.766394        3.905935  \n",
       "Blending_test               0.481936        0.686508        3.905935  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9c1edd5-376e-4a37-ae76-af3143290c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_states = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 100]\n",
    "blending_clf_12 = [get_clf(rnd) for rnd in rnd_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d49c56-c026-4815-93d9-9c7842fee8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(blending_clf_12))):\n",
    "    blending_clf_12[i].fit(X_train, y_train, test_size=0.5, random_state=rnd_states[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be7e4909-31ca-4f34-807c-a5667a1fe643",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    CalibratedClassifierCV(clf, method=\"isotonic\", cv=\"prefit\")\n",
    "    for clf in blending_clf_12\n",
    "]\n",
    "vt_clf_blendings = VotingClassifierCustom(models)\n",
    "vt_clf_blendings.fit(X_val, y_val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cb71d12b-5d9d-4973-b0ba-cf077f11db11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>gini_stability</th>\n",
       "      <th>overfitting, %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_train</th>\n",
       "      <td>0.968692</td>\n",
       "      <td>0.894470</td>\n",
       "      <td>0.618962</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.102074</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_test</th>\n",
       "      <td>0.968575</td>\n",
       "      <td>0.857126</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.014988</td>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.688272</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_train</th>\n",
       "      <td>0.968697</td>\n",
       "      <td>0.893210</td>\n",
       "      <td>0.606811</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.109814</td>\n",
       "      <td>0.770778</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_test</th>\n",
       "      <td>0.968542</td>\n",
       "      <td>0.857288</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>0.116794</td>\n",
       "      <td>0.689036</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_train</th>\n",
       "      <td>0.968654</td>\n",
       "      <td>0.902040</td>\n",
       "      <td>0.649682</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.012528</td>\n",
       "      <td>0.120357</td>\n",
       "      <td>0.790379</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_test</th>\n",
       "      <td>0.968588</td>\n",
       "      <td>0.855851</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.128851</td>\n",
       "      <td>0.684912</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_train</th>\n",
       "      <td>0.772604</td>\n",
       "      <td>0.890391</td>\n",
       "      <td>0.107409</td>\n",
       "      <td>0.852689</td>\n",
       "      <td>0.190785</td>\n",
       "      <td>0.475913</td>\n",
       "      <td>0.766394</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_test</th>\n",
       "      <td>0.769366</td>\n",
       "      <td>0.856921</td>\n",
       "      <td>0.098917</td>\n",
       "      <td>0.781331</td>\n",
       "      <td>0.175603</td>\n",
       "      <td>0.481936</td>\n",
       "      <td>0.686508</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_of_blendings_train</th>\n",
       "      <td>0.968705</td>\n",
       "      <td>0.890886</td>\n",
       "      <td>0.546227</td>\n",
       "      <td>0.026774</td>\n",
       "      <td>0.051047</td>\n",
       "      <td>0.209327</td>\n",
       "      <td>0.767271</td>\n",
       "      <td>3.908178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_of_blendings_test</th>\n",
       "      <td>0.968405</td>\n",
       "      <td>0.857378</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>0.216647</td>\n",
       "      <td>0.687300</td>\n",
       "      <td>3.908178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy   ROC_AUC  Precision    Recall        f1  \\\n",
       "model                                                                           \n",
       "Voting_weighted_auto_train  0.968692  0.894470   0.618962  0.010728  0.021090   \n",
       "Voting_weighted_auto_test   0.968575  0.857126   0.514085  0.007605  0.014988   \n",
       "Voting_weighted_train       0.968697  0.893210   0.606811  0.012154  0.023831   \n",
       "Voting_weighted_test        0.968542  0.857288   0.482558  0.008647  0.016989   \n",
       "Voting_no_weights_train     0.968654  0.902040   0.649682  0.006325  0.012528   \n",
       "Voting_no_weights_test      0.968588  0.855851   0.550000  0.004584  0.009092   \n",
       "Blending_train              0.772604  0.890391   0.107409  0.852689  0.190785   \n",
       "Blending_test               0.769366  0.856921   0.098917  0.781331  0.175603   \n",
       "Voting_of_blendings_train   0.968705  0.890886   0.546227  0.026774  0.051047   \n",
       "Voting_of_blendings_test    0.968405  0.857378   0.444700  0.020106  0.038473   \n",
       "\n",
       "                             Logloss  gini_stability  overfitting, %  \n",
       "model                                                                 \n",
       "Voting_weighted_auto_train  0.102074        0.773653        4.356915  \n",
       "Voting_weighted_auto_test   0.110082        0.688272        4.356915  \n",
       "Voting_weighted_train       0.109814        0.770778        4.190239  \n",
       "Voting_weighted_test        0.116794        0.689036        4.190239  \n",
       "Voting_no_weights_train     0.120357        0.790379        5.396866  \n",
       "Voting_no_weights_test      0.128851        0.684912        5.396866  \n",
       "Blending_train              0.475913        0.766394        3.905935  \n",
       "Blending_test               0.481936        0.686508        3.905935  \n",
       "Voting_of_blendings_train   0.209327        0.767271        3.908178  \n",
       "Voting_of_blendings_test    0.216647        0.687300        3.908178  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_ = metrics_estimation(\n",
    "    vt_clf_blendings,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    weeks_train,\n",
    "    weeks_test,\n",
    "    name=\"Voting_of_blendings\",\n",
    ")\n",
    "metrics = pd.concat([metrics, metrics_])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e40cba-0640-40ef-98e0-083568b1b16e",
   "metadata": {},
   "source": [
    "Просто blending не дал выдающихся результатов, но комбинация VotingClassifierCustom с использованием 12 предобученных BlendingClassifier дает уж значение ROC_AUC 0.857378, что лучше VotingClassifierCustom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2149f2-8354-4d45-9363-50d8d8a14cca",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "26f80240-b19a-49f8-aced-b20325b0a0e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class StackingClassifierCustom(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Stacking Ensemble classifier of multiple estimators and meta estimator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimators : list of (str, estimator)\n",
    "        Base estimators which will be stacked together.\n",
    "        The type of estimator is generally expected to be a classifier.\n",
    "    final_estimator : estimator, default=None\n",
    "        A classifier which will be used to combine the base estimators.\n",
    "        The default classifier is a LogisticRegression.\n",
    "    stack_method : {'predict_proba', 'predict'}, default='predict_proba'\n",
    "        Methods called for each base estimator. It can be:\n",
    "        'predict_proba'  or 'predict'\n",
    "    n_jobs : int, default=-1\n",
    "        The number of jobs to run in parallel all `estimators` `fit`.\n",
    "         -1 means using all processors.\n",
    "         None means use number of base estimators\n",
    "    random_states : list[int], Default=[0]\n",
    "        list of random states for StratifiedGroupKFold\n",
    "    n_splits : int, default=5\n",
    "        n_splits for StratifiedGroupKFold\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimators: list,\n",
    "        final_estimator=None,\n",
    "        stack_method: str = \"predict_proba\",\n",
    "        n_jobs: int | None = None,\n",
    "        random_states: list | None = None,\n",
    "        n_splits: int = 5,\n",
    "    ):\n",
    "        assert len(estimators) > 1, \"More than 1 estimators must be passed.\"\n",
    "        assert (\n",
    "            isinstance(random_states, list) or random_states is None\n",
    "        ), \"random_states must be list[int]\"\n",
    "        self.estimators = estimators\n",
    "        self.final_estimator = (\n",
    "            LogisticRegression(class_weight=\"balanced\", n_jobs=-1)\n",
    "            if final_estimator is None\n",
    "            else final_estimator\n",
    "        )\n",
    "        self.n_jobs = len(estimators) if n_jobs is None else n_jobs\n",
    "        self.stack_method = stack_method\n",
    "        self.random_states = [0] if random_states is None else random_states\n",
    "        self.n_splits = n_splits\n",
    "        self.fit_params = {\n",
    "            \"CatBoostClassifier\": {\"early_stopping_rounds\": 100, \"verbose\": 0},\n",
    "            \"LGBMClassifier\": {\n",
    "                \"eval_metric\": \"auc\",\n",
    "                \"callbacks\": [early_stopping(stopping_rounds=100, verbose=0)],\n",
    "            },\n",
    "            \"XGBClassifier\": {\"verbose\": 0},\n",
    "        }\n",
    "\n",
    "    def __sklearn_is_fitted__(self) -> bool:\n",
    "        \"\"\"Perform is_fitted validation for final estimator.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: bool\n",
    "        \"\"\"\n",
    "        return check_is_fitted(self.final_estimator)\n",
    "\n",
    "    def _meta_X(self, X: pd.DataFrame | np.ndarray) -> pd.DataFrame:\n",
    "        \"\"\"Generate meta data using fitted base estimators\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        meta_X : pd.DataFrame\n",
    "            Meta data for meta estimator\n",
    "        \"\"\"\n",
    "        assert self.stack_method in [\n",
    "            \"predict_proba\",\n",
    "            \"predict\",\n",
    "        ], \"stack_method not passed\"\n",
    "        if self.stack_method == \"predict_proba\":\n",
    "            X_pred = (delayed(self.proba)(est, X) for est in self.estimators_)\n",
    "        elif self.stack_method == \"predict\":\n",
    "            X_pred = (delayed(est.predict)(X) for est in self.estimators_)\n",
    "        X_pred = Parallel(n_jobs=self.n_jobs)(X_pred)\n",
    "        meta_X = pd.DataFrame(X_pred).T\n",
    "        return meta_X\n",
    "\n",
    "    def _fit_base_estimators(\n",
    "        self, X: pd.DataFrame | np.ndarray, y: pd.Series | np.ndarray\n",
    "    ) -> None:\n",
    "        \"\"\"Fit base estimators.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(est.fit)(X, y) for _, est in self.estimators\n",
    "        )\n",
    "        return\n",
    "\n",
    "    def crossval_predict(\n",
    "        self,\n",
    "        model: BaseEstimator,\n",
    "        X: pd.DataFrame | np.ndarray,\n",
    "        y: pd.Series | np.ndarray,\n",
    "        groups: pd.Series | np.ndarray | None = None,\n",
    "        cv_rnd: int = 0,\n",
    "        verbose: int = 0,\n",
    "    ) -> tuple:\n",
    "        \"\"\"Generate meta data using StratifiedGroupKFold\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : BaseEstimator\n",
    "\n",
    "        X : {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        y: array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "\n",
    "        groups : pd.Series | np.ndarray,\n",
    "            Weeks using for StratifiedGroupKFold as groups\n",
    "\n",
    "        cv_rnd : int, default=0\n",
    "        random_state for StratifiedGroupKFold\n",
    "\n",
    "        verbose: int, Default=0\n",
    "            If != 0 show ROC AUC score for each fold\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: tuple of meta_X, meta_y\n",
    "            Meta data for meta estimator\n",
    "        \"\"\"\n",
    "        meta_X, meta_y = [], []\n",
    "        cv = StratifiedGroupKFold(self.n_splits, True, cv_rnd)\n",
    "        for idx, (train_idx, val_idx) in enumerate(cv.split(X, y, groups=groups)):\n",
    "            X_train_cv, X_val_cv = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_cv, y_val_cv = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            model.fit(\n",
    "                X_train_cv,\n",
    "                y_train_cv,\n",
    "                eval_set=[(X_val_cv, y_val_cv)],\n",
    "                **self.fit_params[model.__class__.__name__],\n",
    "            )\n",
    "            y_score = model.predict_proba(X_val_cv)\n",
    "            if verbose != 0:\n",
    "                msg = f\"{model.__class__.__name__} for rnd_state={cv_rnd} Fold: {idx} ROC-AUC score {roc_auc_score(y_val_cv, y_score[:, 1])}\"\n",
    "                print(msg)\n",
    "            if self.stack_method == \"predict_proba\":\n",
    "                meta_X.append(y_score)\n",
    "            else:\n",
    "                y_pred = model.predict(X_val_cv)\n",
    "                meta_X.append(y_pred)\n",
    "            meta_y.append(y_val_cv)\n",
    "        meta_X = np.concatenate(meta_X)\n",
    "        meta_X = meta_X[:, 1] if self.stack_method == \"predict_proba\" else meta_X\n",
    "        meta_y = np.concatenate(meta_y)\n",
    "        return meta_X, meta_y\n",
    "\n",
    "    def _meta_data_train(\n",
    "        self, X: pd.DataFrame | np.ndarray, y: pd.Series | np.ndarray, **kwargs\n",
    "    ) -> tuple:\n",
    "        \"\"\"\n",
    "        Get meta data for train.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        y: array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : tuple of (meta_X, meta_y)\n",
    "            Meta data\n",
    "        \"\"\"\n",
    "        meta_X = pd.DataFrame()\n",
    "        meta_X_y = (\n",
    "            delayed(self._meta_data_train_one_rnd)(X, y, cv_rnd=i, **kwargs)\n",
    "            for i in self.random_states\n",
    "        )\n",
    "        meta_X_y = Parallel(n_jobs=self.n_jobs)(meta_X_y)\n",
    "        meta_X = pd.concat([x for x, _ in meta_X_y])\n",
    "        meta_y = np.concatenate([y for _, y in meta_X_y])\n",
    "        return meta_X, meta_y\n",
    "\n",
    "    def _meta_data_train_one_rnd(\n",
    "        self, X: pd.DataFrame | np.ndarray, y: pd.Series | np.ndarray, **kwargs\n",
    "    ) -> tuple:\n",
    "        \"\"\"\n",
    "        Get meta data for train for one current random state of KFolds\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        y: array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : tuple of (meta_X, meta_y)\n",
    "            Meta data\n",
    "        \"\"\"\n",
    "        meta_X = pd.DataFrame()\n",
    "        meta_X_y = (\n",
    "            delayed(self.crossval_predict)(est, X, y, **kwargs)\n",
    "            for _, est in self.estimators\n",
    "        )\n",
    "        meta_X_y = Parallel(n_jobs=self.n_jobs)(meta_X_y)\n",
    "        for i, (meta_X_, meta_y_) in enumerate(meta_X_y):\n",
    "            est_name = self.estimators[i][0]\n",
    "            meta_X[est_name] = meta_X_\n",
    "            meta_y = meta_y_\n",
    "        return meta_X, meta_y\n",
    "\n",
    "    def fit(self, X: pd.DataFrame | np.ndarray, y: pd.Series | np.ndarray, **kwargs):\n",
    "        \"\"\"Fit the final_estimator on meta data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        y: array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns the instance itself.\n",
    "        \"\"\"\n",
    "\n",
    "        meta_X, meta_y = self._meta_data_train(X, y, **kwargs)\n",
    "        self._fit_base_estimators(X, y)\n",
    "        self.final_estimator.fit(meta_X, meta_y)\n",
    "        self.classes_ = self.final_estimator.classes_\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: pd.DataFrame | np.ndarray) -> np.array:\n",
    "        \"\"\"Predict class labels for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : array-like of shape (n_samples,)\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        meta_X = self._meta_X(X)\n",
    "        y_pred = self.final_estimator.predict(meta_X)\n",
    "        return y_pred\n",
    "\n",
    "    def predict_proba(self, X: pd.DataFrame | np.ndarray) -> np.array:\n",
    "        \"\"\"Compute probabilities of possible outcomes for samples in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_scores : array-like of shape (n_samples, n_classes)\n",
    "            Weighted probability for each class per sample.\n",
    "        \"\"\"\n",
    "        meta_X = self._meta_X(X)\n",
    "        y_scores = self.final_estimator.predict_proba(meta_X)\n",
    "        return y_scores\n",
    "\n",
    "    @staticmethod\n",
    "    def proba(estimator: BaseEstimator, X: pd.DataFrame | np.ndarray) -> np.ndarray:\n",
    "        \"\"\"predict_proba and return column 1\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        estimator: BaseEstimator\n",
    "\n",
    "        X : {array-like, sparse matrix, DataFrame} of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_scores : array-like of shape (n_samples, n_classes)\n",
    "            Weighted probability for each class per sample.\n",
    "        \"\"\"\n",
    "        y_scores = estimator.predict_proba(X)[:, 1]\n",
    "        return y_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e854f0-4b69-4ea6-94c2-e9df88b99b53",
   "metadata": {},
   "source": [
    "## Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9c1a125-a0b4-40a9-aa2e-4cb51141d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_catboost = CatBoostClassifier(\n",
    "    random_state=0,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    verbose=0,\n",
    "    **params[\"cat_boost\"],\n",
    "    **best_params[\"cat_boost\"]\n",
    ")\n",
    "\n",
    "clf_lgb = LGBMClassifier(\n",
    "    random_state=0,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    **params[\"lgbm\"],\n",
    "    **best_params[\"lgbm\"]\n",
    ")\n",
    "\n",
    "clf_xgb = XGBClassifier(\n",
    "    random_state=0,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric=\"auc\",\n",
    "    verbose=0,\n",
    "    **params[\"xgb\"],\n",
    "    **best_params[\"xgb\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b54ce7b-b892-4195-a92e-4cda7c1a290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"lgb\", clf_lgb), (\"cat\", clf_catboost), (\"xgb\", clf_xgb)]\n",
    "final_estimator = LogisticRegression(\n",
    "    class_weight=\"balanced\", random_state=RAND, n_jobs=24\n",
    ")\n",
    "clf = StackingClassifierCustom(\n",
    "    estimators, final_estimator, n_jobs=1, n_splits=5, random_states=[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67bdf2-b359-4e2d-93da-40e4d5f49651",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, groups=weeks_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0747a93b-d97b-4e6e-81d3-5d68c7394073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>gini_stability</th>\n",
       "      <th>overfitting, %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_train</th>\n",
       "      <td>0.968692</td>\n",
       "      <td>0.894470</td>\n",
       "      <td>0.618962</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.102074</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_test</th>\n",
       "      <td>0.968575</td>\n",
       "      <td>0.857126</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.014988</td>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.688272</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_train</th>\n",
       "      <td>0.968697</td>\n",
       "      <td>0.893210</td>\n",
       "      <td>0.606811</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.109814</td>\n",
       "      <td>0.770778</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_test</th>\n",
       "      <td>0.968542</td>\n",
       "      <td>0.857288</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>0.116794</td>\n",
       "      <td>0.689036</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_train</th>\n",
       "      <td>0.968654</td>\n",
       "      <td>0.902040</td>\n",
       "      <td>0.649682</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.012528</td>\n",
       "      <td>0.120357</td>\n",
       "      <td>0.790379</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_test</th>\n",
       "      <td>0.968588</td>\n",
       "      <td>0.855851</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.128851</td>\n",
       "      <td>0.684912</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_train</th>\n",
       "      <td>0.772604</td>\n",
       "      <td>0.890391</td>\n",
       "      <td>0.107409</td>\n",
       "      <td>0.852689</td>\n",
       "      <td>0.190785</td>\n",
       "      <td>0.475913</td>\n",
       "      <td>0.766394</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_test</th>\n",
       "      <td>0.769366</td>\n",
       "      <td>0.856921</td>\n",
       "      <td>0.098917</td>\n",
       "      <td>0.781331</td>\n",
       "      <td>0.175603</td>\n",
       "      <td>0.481936</td>\n",
       "      <td>0.686508</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_of_blendings_train</th>\n",
       "      <td>0.968705</td>\n",
       "      <td>0.890886</td>\n",
       "      <td>0.546227</td>\n",
       "      <td>0.026774</td>\n",
       "      <td>0.051047</td>\n",
       "      <td>0.209327</td>\n",
       "      <td>0.767271</td>\n",
       "      <td>3.908178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_of_blendings_test</th>\n",
       "      <td>0.968405</td>\n",
       "      <td>0.857378</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>0.216647</td>\n",
       "      <td>0.687300</td>\n",
       "      <td>3.908178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_tuned_0_train</th>\n",
       "      <td>0.779456</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.113386</td>\n",
       "      <td>0.882094</td>\n",
       "      <td>0.200942</td>\n",
       "      <td>0.458677</td>\n",
       "      <td>0.798335</td>\n",
       "      <td>5.372485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_tuned_0_test</th>\n",
       "      <td>0.774518</td>\n",
       "      <td>0.859248</td>\n",
       "      <td>0.100991</td>\n",
       "      <td>0.781123</td>\n",
       "      <td>0.178858</td>\n",
       "      <td>0.467763</td>\n",
       "      <td>0.691879</td>\n",
       "      <td>5.372485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy   ROC_AUC  Precision    Recall        f1  \\\n",
       "model                                                                           \n",
       "Voting_weighted_auto_train  0.968692  0.894470   0.618962  0.010728  0.021090   \n",
       "Voting_weighted_auto_test   0.968575  0.857126   0.514085  0.007605  0.014988   \n",
       "Voting_weighted_train       0.968697  0.893210   0.606811  0.012154  0.023831   \n",
       "Voting_weighted_test        0.968542  0.857288   0.482558  0.008647  0.016989   \n",
       "Voting_no_weights_train     0.968654  0.902040   0.649682  0.006325  0.012528   \n",
       "Voting_no_weights_test      0.968588  0.855851   0.550000  0.004584  0.009092   \n",
       "Blending_train              0.772604  0.890391   0.107409  0.852689  0.190785   \n",
       "Blending_test               0.769366  0.856921   0.098917  0.781331  0.175603   \n",
       "Voting_of_blendings_train   0.968705  0.890886   0.546227  0.026774  0.051047   \n",
       "Voting_of_blendings_test    0.968405  0.857378   0.444700  0.020106  0.038473   \n",
       "Stacking_tuned_0_train      0.779456  0.905411   0.113386  0.882094  0.200942   \n",
       "Stacking_tuned_0_test       0.774518  0.859248   0.100991  0.781123  0.178858   \n",
       "\n",
       "                             Logloss  gini_stability  overfitting, %  \n",
       "model                                                                 \n",
       "Voting_weighted_auto_train  0.102074        0.773653        4.356915  \n",
       "Voting_weighted_auto_test   0.110082        0.688272        4.356915  \n",
       "Voting_weighted_train       0.109814        0.770778        4.190239  \n",
       "Voting_weighted_test        0.116794        0.689036        4.190239  \n",
       "Voting_no_weights_train     0.120357        0.790379        5.396866  \n",
       "Voting_no_weights_test      0.128851        0.684912        5.396866  \n",
       "Blending_train              0.475913        0.766394        3.905935  \n",
       "Blending_test               0.481936        0.686508        3.905935  \n",
       "Voting_of_blendings_train   0.209327        0.767271        3.908178  \n",
       "Voting_of_blendings_test    0.216647        0.687300        3.908178  \n",
       "Stacking_tuned_0_train      0.458677        0.798335        5.372485  \n",
       "Stacking_tuned_0_test       0.467763        0.691879        5.372485  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_ = metrics_estimation(\n",
    "    clf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    weeks_train,\n",
    "    weeks_test,\n",
    "    name=\"Stacking_tuned_0\",\n",
    ")\n",
    "metrics = pd.concat([metrics, metrics_])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ff6df-6343-4789-9f0e-4e526031f7cb",
   "metadata": {},
   "source": [
    "## Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "380aff0d-b720-4cdd-acb8-fa9bc4cd3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_catboost_baseline = CatBoostClassifier(\n",
    "    random_state=0, scale_pos_weight=scale_pos_weight, verbose=0, **params[\"cat_boost\"]\n",
    ")\n",
    "\n",
    "clf_lgb_baseline = LGBMClassifier(\n",
    "    random_state=0, scale_pos_weight=scale_pos_weight, **params[\"lgbm\"]\n",
    ")\n",
    "\n",
    "clf_xgb_baseline = XGBClassifier(\n",
    "    random_state=0,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric=\"auc\",\n",
    "    verbose=0,\n",
    "    **params[\"xgb\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0a8e972-6f76-4b3f-a70d-083a5c447d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    (\"lgb\", clf_lgb_baseline),\n",
    "    (\"cat\", clf_catboost_baseline),\n",
    "    (\"xgb\", clf_xgb_baseline),\n",
    "]\n",
    "final_estimator = LogisticRegression(class_weight=\"balanced\", random_state=0, n_jobs=24)\n",
    "clf_baseline = StackingClassifierCustom(\n",
    "    estimators, final_estimator, n_jobs=1, n_splits=5, random_states=[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d85c536-8c03-4ba6-ac8d-6dbfb8b127e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_baseline.fit(X_train, y_train, groups=weeks_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f7c0f1ff-64a8-42ec-a64c-4129c2122f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>gini_stability</th>\n",
       "      <th>overfitting, %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_train</th>\n",
       "      <td>0.968692</td>\n",
       "      <td>0.894470</td>\n",
       "      <td>0.618962</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.102074</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_test</th>\n",
       "      <td>0.968575</td>\n",
       "      <td>0.857126</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.014988</td>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.688272</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_train</th>\n",
       "      <td>0.968697</td>\n",
       "      <td>0.893210</td>\n",
       "      <td>0.606811</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.109814</td>\n",
       "      <td>0.770778</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_test</th>\n",
       "      <td>0.968542</td>\n",
       "      <td>0.857288</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>0.116794</td>\n",
       "      <td>0.689036</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_train</th>\n",
       "      <td>0.968654</td>\n",
       "      <td>0.902040</td>\n",
       "      <td>0.649682</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.012528</td>\n",
       "      <td>0.120357</td>\n",
       "      <td>0.790379</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_test</th>\n",
       "      <td>0.968588</td>\n",
       "      <td>0.855851</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.128851</td>\n",
       "      <td>0.684912</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_train</th>\n",
       "      <td>0.772604</td>\n",
       "      <td>0.890391</td>\n",
       "      <td>0.107409</td>\n",
       "      <td>0.852689</td>\n",
       "      <td>0.190785</td>\n",
       "      <td>0.475913</td>\n",
       "      <td>0.766394</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_test</th>\n",
       "      <td>0.769366</td>\n",
       "      <td>0.856921</td>\n",
       "      <td>0.098917</td>\n",
       "      <td>0.781331</td>\n",
       "      <td>0.175603</td>\n",
       "      <td>0.481936</td>\n",
       "      <td>0.686508</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_of_blendings_train</th>\n",
       "      <td>0.968705</td>\n",
       "      <td>0.890886</td>\n",
       "      <td>0.546227</td>\n",
       "      <td>0.026774</td>\n",
       "      <td>0.051047</td>\n",
       "      <td>0.209327</td>\n",
       "      <td>0.767271</td>\n",
       "      <td>3.908178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_of_blendings_test</th>\n",
       "      <td>0.968405</td>\n",
       "      <td>0.857378</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>0.216647</td>\n",
       "      <td>0.687300</td>\n",
       "      <td>3.908178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_tuned_0_train</th>\n",
       "      <td>0.779456</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.113386</td>\n",
       "      <td>0.882094</td>\n",
       "      <td>0.200942</td>\n",
       "      <td>0.458677</td>\n",
       "      <td>0.798335</td>\n",
       "      <td>5.372485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_tuned_0_test</th>\n",
       "      <td>0.774518</td>\n",
       "      <td>0.859248</td>\n",
       "      <td>0.100991</td>\n",
       "      <td>0.781123</td>\n",
       "      <td>0.178858</td>\n",
       "      <td>0.467763</td>\n",
       "      <td>0.691879</td>\n",
       "      <td>5.372485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline_0_train</th>\n",
       "      <td>0.751777</td>\n",
       "      <td>0.866733</td>\n",
       "      <td>0.096302</td>\n",
       "      <td>0.822503</td>\n",
       "      <td>0.172417</td>\n",
       "      <td>0.501353</td>\n",
       "      <td>0.713617</td>\n",
       "      <td>1.973197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline_0_test</th>\n",
       "      <td>0.751385</td>\n",
       "      <td>0.849962</td>\n",
       "      <td>0.093039</td>\n",
       "      <td>0.789666</td>\n",
       "      <td>0.166465</td>\n",
       "      <td>0.503349</td>\n",
       "      <td>0.668484</td>\n",
       "      <td>1.973197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy   ROC_AUC  Precision    Recall        f1  \\\n",
       "model                                                                           \n",
       "Voting_weighted_auto_train  0.968692  0.894470   0.618962  0.010728  0.021090   \n",
       "Voting_weighted_auto_test   0.968575  0.857126   0.514085  0.007605  0.014988   \n",
       "Voting_weighted_train       0.968697  0.893210   0.606811  0.012154  0.023831   \n",
       "Voting_weighted_test        0.968542  0.857288   0.482558  0.008647  0.016989   \n",
       "Voting_no_weights_train     0.968654  0.902040   0.649682  0.006325  0.012528   \n",
       "Voting_no_weights_test      0.968588  0.855851   0.550000  0.004584  0.009092   \n",
       "Blending_train              0.772604  0.890391   0.107409  0.852689  0.190785   \n",
       "Blending_test               0.769366  0.856921   0.098917  0.781331  0.175603   \n",
       "Voting_of_blendings_train   0.968705  0.890886   0.546227  0.026774  0.051047   \n",
       "Voting_of_blendings_test    0.968405  0.857378   0.444700  0.020106  0.038473   \n",
       "Stacking_tuned_0_train      0.779456  0.905411   0.113386  0.882094  0.200942   \n",
       "Stacking_tuned_0_test       0.774518  0.859248   0.100991  0.781123  0.178858   \n",
       "Stacking_baseline_0_train   0.751777  0.866733   0.096302  0.822503  0.172417   \n",
       "Stacking_baseline_0_test    0.751385  0.849962   0.093039  0.789666  0.166465   \n",
       "\n",
       "                             Logloss  gini_stability  overfitting, %  \n",
       "model                                                                 \n",
       "Voting_weighted_auto_train  0.102074        0.773653        4.356915  \n",
       "Voting_weighted_auto_test   0.110082        0.688272        4.356915  \n",
       "Voting_weighted_train       0.109814        0.770778        4.190239  \n",
       "Voting_weighted_test        0.116794        0.689036        4.190239  \n",
       "Voting_no_weights_train     0.120357        0.790379        5.396866  \n",
       "Voting_no_weights_test      0.128851        0.684912        5.396866  \n",
       "Blending_train              0.475913        0.766394        3.905935  \n",
       "Blending_test               0.481936        0.686508        3.905935  \n",
       "Voting_of_blendings_train   0.209327        0.767271        3.908178  \n",
       "Voting_of_blendings_test    0.216647        0.687300        3.908178  \n",
       "Stacking_tuned_0_train      0.458677        0.798335        5.372485  \n",
       "Stacking_tuned_0_test       0.467763        0.691879        5.372485  \n",
       "Stacking_baseline_0_train   0.501353        0.713617        1.973197  \n",
       "Stacking_baseline_0_test    0.503349        0.668484        1.973197  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_ = metrics_estimation(\n",
    "    clf_baseline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    weeks_train,\n",
    "    weeks_test,\n",
    "    name=\"Stacking_baseline_0\",\n",
    ")\n",
    "metrics = pd.concat([metrics, metrics_])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c811395f-7feb-4504-b4b7-9cb6a214811b",
   "metadata": {},
   "source": [
    "## Tuned + baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "109579b0-eb1f-43fc-a6d0-3fe374b79cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    (\"lgb_b\", clf_lgb_baseline),\n",
    "    (\"cat_b\", clf_catboost_baseline),\n",
    "    (\"xgb_b\", clf_xgb_baseline),\n",
    "    (\"lgb\", clf_lgb),\n",
    "    (\"cat\", clf_catboost),\n",
    "    (\"xgb\", clf_xgb),\n",
    "]\n",
    "final_estimator = LogisticRegression(class_weight=\"balanced\", random_state=0, n_jobs=24)\n",
    "clf = StackingClassifierCustom(\n",
    "    estimators, final_estimator, n_jobs=1, n_splits=5, random_states=[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa5583b-712a-4905-84b5-9f5f60ce9559",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, groups=weeks_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "33580f08-6aff-4d00-a0b1-faa6a29a622e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>gini_stability</th>\n",
       "      <th>overfitting, %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_train</th>\n",
       "      <td>0.968692</td>\n",
       "      <td>0.894470</td>\n",
       "      <td>0.618962</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.102074</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_test</th>\n",
       "      <td>0.968575</td>\n",
       "      <td>0.857126</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.014988</td>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.688272</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_train</th>\n",
       "      <td>0.968697</td>\n",
       "      <td>0.893210</td>\n",
       "      <td>0.606811</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.109814</td>\n",
       "      <td>0.770778</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_test</th>\n",
       "      <td>0.968542</td>\n",
       "      <td>0.857288</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>0.116794</td>\n",
       "      <td>0.689036</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_train</th>\n",
       "      <td>0.968654</td>\n",
       "      <td>0.902040</td>\n",
       "      <td>0.649682</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.012528</td>\n",
       "      <td>0.120357</td>\n",
       "      <td>0.790379</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_test</th>\n",
       "      <td>0.968588</td>\n",
       "      <td>0.855851</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.128851</td>\n",
       "      <td>0.684912</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_train</th>\n",
       "      <td>0.772604</td>\n",
       "      <td>0.890391</td>\n",
       "      <td>0.107409</td>\n",
       "      <td>0.852689</td>\n",
       "      <td>0.190785</td>\n",
       "      <td>0.475913</td>\n",
       "      <td>0.766394</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_test</th>\n",
       "      <td>0.769366</td>\n",
       "      <td>0.856921</td>\n",
       "      <td>0.098917</td>\n",
       "      <td>0.781331</td>\n",
       "      <td>0.175603</td>\n",
       "      <td>0.481936</td>\n",
       "      <td>0.686508</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_of_blendings_train</th>\n",
       "      <td>0.968705</td>\n",
       "      <td>0.890886</td>\n",
       "      <td>0.546227</td>\n",
       "      <td>0.026774</td>\n",
       "      <td>0.051047</td>\n",
       "      <td>0.209327</td>\n",
       "      <td>0.767271</td>\n",
       "      <td>3.908178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_of_blendings_test</th>\n",
       "      <td>0.968405</td>\n",
       "      <td>0.857378</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>0.216647</td>\n",
       "      <td>0.687300</td>\n",
       "      <td>3.908178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_tuned_0_train</th>\n",
       "      <td>0.779456</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.113386</td>\n",
       "      <td>0.882094</td>\n",
       "      <td>0.200942</td>\n",
       "      <td>0.458677</td>\n",
       "      <td>0.798335</td>\n",
       "      <td>5.372485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_tuned_0_test</th>\n",
       "      <td>0.774518</td>\n",
       "      <td>0.859248</td>\n",
       "      <td>0.100991</td>\n",
       "      <td>0.781123</td>\n",
       "      <td>0.178858</td>\n",
       "      <td>0.467763</td>\n",
       "      <td>0.691879</td>\n",
       "      <td>5.372485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline_0_train</th>\n",
       "      <td>0.751777</td>\n",
       "      <td>0.866733</td>\n",
       "      <td>0.096302</td>\n",
       "      <td>0.822503</td>\n",
       "      <td>0.172417</td>\n",
       "      <td>0.501353</td>\n",
       "      <td>0.713617</td>\n",
       "      <td>1.973197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline_0_test</th>\n",
       "      <td>0.751385</td>\n",
       "      <td>0.849962</td>\n",
       "      <td>0.093039</td>\n",
       "      <td>0.789666</td>\n",
       "      <td>0.166465</td>\n",
       "      <td>0.503349</td>\n",
       "      <td>0.668484</td>\n",
       "      <td>1.973197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline+tuned_0_train</th>\n",
       "      <td>0.777784</td>\n",
       "      <td>0.901936</td>\n",
       "      <td>0.111903</td>\n",
       "      <td>0.874906</td>\n",
       "      <td>0.198427</td>\n",
       "      <td>0.461049</td>\n",
       "      <td>0.790888</td>\n",
       "      <td>4.991808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline+tuned_0_test</th>\n",
       "      <td>0.773201</td>\n",
       "      <td>0.859054</td>\n",
       "      <td>0.100704</td>\n",
       "      <td>0.783623</td>\n",
       "      <td>0.178473</td>\n",
       "      <td>0.469365</td>\n",
       "      <td>0.691422</td>\n",
       "      <td>4.991808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "model                                                                      \n",
       "Voting_weighted_auto_train       0.968692  0.894470   0.618962  0.010728   \n",
       "Voting_weighted_auto_test        0.968575  0.857126   0.514085  0.007605   \n",
       "Voting_weighted_train            0.968697  0.893210   0.606811  0.012154   \n",
       "Voting_weighted_test             0.968542  0.857288   0.482558  0.008647   \n",
       "Voting_no_weights_train          0.968654  0.902040   0.649682  0.006325   \n",
       "Voting_no_weights_test           0.968588  0.855851   0.550000  0.004584   \n",
       "Blending_train                   0.772604  0.890391   0.107409  0.852689   \n",
       "Blending_test                    0.769366  0.856921   0.098917  0.781331   \n",
       "Voting_of_blendings_train        0.968705  0.890886   0.546227  0.026774   \n",
       "Voting_of_blendings_test         0.968405  0.857378   0.444700  0.020106   \n",
       "Stacking_tuned_0_train           0.779456  0.905411   0.113386  0.882094   \n",
       "Stacking_tuned_0_test            0.774518  0.859248   0.100991  0.781123   \n",
       "Stacking_baseline_0_train        0.751777  0.866733   0.096302  0.822503   \n",
       "Stacking_baseline_0_test         0.751385  0.849962   0.093039  0.789666   \n",
       "Stacking_baseline+tuned_0_train  0.777784  0.901936   0.111903  0.874906   \n",
       "Stacking_baseline+tuned_0_test   0.773201  0.859054   0.100704  0.783623   \n",
       "\n",
       "                                       f1   Logloss  gini_stability  \\\n",
       "model                                                                 \n",
       "Voting_weighted_auto_train       0.021090  0.102074        0.773653   \n",
       "Voting_weighted_auto_test        0.014988  0.110082        0.688272   \n",
       "Voting_weighted_train            0.023831  0.109814        0.770778   \n",
       "Voting_weighted_test             0.016989  0.116794        0.689036   \n",
       "Voting_no_weights_train          0.012528  0.120357        0.790379   \n",
       "Voting_no_weights_test           0.009092  0.128851        0.684912   \n",
       "Blending_train                   0.190785  0.475913        0.766394   \n",
       "Blending_test                    0.175603  0.481936        0.686508   \n",
       "Voting_of_blendings_train        0.051047  0.209327        0.767271   \n",
       "Voting_of_blendings_test         0.038473  0.216647        0.687300   \n",
       "Stacking_tuned_0_train           0.200942  0.458677        0.798335   \n",
       "Stacking_tuned_0_test            0.178858  0.467763        0.691879   \n",
       "Stacking_baseline_0_train        0.172417  0.501353        0.713617   \n",
       "Stacking_baseline_0_test         0.166465  0.503349        0.668484   \n",
       "Stacking_baseline+tuned_0_train  0.198427  0.461049        0.790888   \n",
       "Stacking_baseline+tuned_0_test   0.178473  0.469365        0.691422   \n",
       "\n",
       "                                 overfitting, %  \n",
       "model                                            \n",
       "Voting_weighted_auto_train             4.356915  \n",
       "Voting_weighted_auto_test              4.356915  \n",
       "Voting_weighted_train                  4.190239  \n",
       "Voting_weighted_test                   4.190239  \n",
       "Voting_no_weights_train                5.396866  \n",
       "Voting_no_weights_test                 5.396866  \n",
       "Blending_train                         3.905935  \n",
       "Blending_test                          3.905935  \n",
       "Voting_of_blendings_train              3.908178  \n",
       "Voting_of_blendings_test               3.908178  \n",
       "Stacking_tuned_0_train                 5.372485  \n",
       "Stacking_tuned_0_test                  5.372485  \n",
       "Stacking_baseline_0_train              1.973197  \n",
       "Stacking_baseline_0_test               1.973197  \n",
       "Stacking_baseline+tuned_0_train        4.991808  \n",
       "Stacking_baseline+tuned_0_test         4.991808  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_ = metrics_estimation(\n",
    "    clf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    weeks_train,\n",
    "    weeks_test,\n",
    "    name=\"Stacking_baseline+tuned_0\",\n",
    ")\n",
    "metrics = pd.concat([metrics, metrics_])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71563e49-459f-434c-82cd-5ab486bc2fe3",
   "metadata": {},
   "source": [
    "## Sklearn StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c96637e-a816-4809-ac2e-687cb6c3c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"cat\", clf_catboost), (\"lgb\", clf_lgb), (\"xgb\", clf_xgb)]\n",
    "final_estimator = LogisticRegression(\n",
    "    class_weight=\"balanced\", random_state=RAND, n_jobs=24\n",
    ")\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "clf_sklearn = StackingClassifier(estimators, final_estimator, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3d629b86-739c-47f0-b157-739b24cf5d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=StratifiedKFold(n_splits=5,\n",
       "        random_state=RandomState(MT19937) at 0x2411FFF4340, shuffle=False),\n",
       "                   estimators=[(&#x27;cat&#x27;,\n",
       "                                &lt;catboost.core.CatBoostClassifier object at 0x0000023E9F4B00A0&gt;),\n",
       "                               (&#x27;lgb&#x27;,\n",
       "                                LGBMClassifier(boosting=&#x27;dart&#x27;,\n",
       "                                               colsample_bytree=0.5485996287336528,\n",
       "                                               learning_rate=0.1954073518029098,\n",
       "                                               max_depth=15,\n",
       "                                               min_child_samples=1000,\n",
       "                                               min_split_gai...\n",
       "                                              learning_rate=0.030200548141930312,\n",
       "                                              max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=6,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=5, missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=2000, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=0, ...))],\n",
       "                   final_estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                      n_jobs=24,\n",
       "                                                      random_state=0))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=StratifiedKFold(n_splits=5,\n",
       "        random_state=RandomState(MT19937) at 0x2411FFF4340, shuffle=False),\n",
       "                   estimators=[(&#x27;cat&#x27;,\n",
       "                                &lt;catboost.core.CatBoostClassifier object at 0x0000023E9F4B00A0&gt;),\n",
       "                               (&#x27;lgb&#x27;,\n",
       "                                LGBMClassifier(boosting=&#x27;dart&#x27;,\n",
       "                                               colsample_bytree=0.5485996287336528,\n",
       "                                               learning_rate=0.1954073518029098,\n",
       "                                               max_depth=15,\n",
       "                                               min_child_samples=1000,\n",
       "                                               min_split_gai...\n",
       "                                              learning_rate=0.030200548141930312,\n",
       "                                              max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=6,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=5, missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=2000, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=0, ...))],\n",
       "                   final_estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                      n_jobs=24,\n",
       "                                                      random_state=0))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cat</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x0000023E9F4B00A0&gt;</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(boosting=&#x27;dart&#x27;, colsample_bytree=0.5485996287336528,\n",
       "               learning_rate=0.1954073518029098, max_depth=15,\n",
       "               min_child_samples=1000, min_split_gain=0, n_jobs=24,\n",
       "               num_leaves=1060, random_state=0, reg_alpha=540, reg_lambda=810,\n",
       "               scale_pos_weight=30.8093141510604, subsample=0.2870356371135097,\n",
       "               verbose=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=0.2682056222912268,\n",
       "              colsample_bynode=0.7786367353875768,\n",
       "              colsample_bytree=0.963466000130137, device=&#x27;cuda&#x27;,\n",
       "              early_stopping_rounds=None, enable_categorical=True,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.030200548141930312, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=2000, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=0, ...)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, n_jobs=24, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(cv=StratifiedKFold(n_splits=5,\n",
       "        random_state=RandomState(MT19937) at 0x2411FFF4340, shuffle=False),\n",
       "                   estimators=[('cat',\n",
       "                                <catboost.core.CatBoostClassifier object at 0x0000023E9F4B00A0>),\n",
       "                               ('lgb',\n",
       "                                LGBMClassifier(boosting='dart',\n",
       "                                               colsample_bytree=0.5485996287336528,\n",
       "                                               learning_rate=0.1954073518029098,\n",
       "                                               max_depth=15,\n",
       "                                               min_child_samples=1000,\n",
       "                                               min_split_gai...\n",
       "                                              learning_rate=0.030200548141930312,\n",
       "                                              max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=6,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=5, missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=2000, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=0, ...))],\n",
       "                   final_estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                      n_jobs=24,\n",
       "                                                      random_state=0))"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sklearn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "92bd758a-5644-4186-8888-bfd83f47a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stacking_sklearn.bin\", \"wb\") as fout:\n",
    "    dill.dump(clf_sklearn, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "64f01bd3-8e55-48fe-8897-0f347309bbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>gini_stability</th>\n",
       "      <th>overfitting, %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_train</th>\n",
       "      <td>0.968692</td>\n",
       "      <td>0.894470</td>\n",
       "      <td>0.618962</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.102074</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_test</th>\n",
       "      <td>0.968575</td>\n",
       "      <td>0.857126</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.014988</td>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.688272</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_train</th>\n",
       "      <td>0.968697</td>\n",
       "      <td>0.893210</td>\n",
       "      <td>0.606811</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.109814</td>\n",
       "      <td>0.770778</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_test</th>\n",
       "      <td>0.968542</td>\n",
       "      <td>0.857288</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>0.116794</td>\n",
       "      <td>0.689036</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_train</th>\n",
       "      <td>0.968654</td>\n",
       "      <td>0.902040</td>\n",
       "      <td>0.649682</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.012528</td>\n",
       "      <td>0.120357</td>\n",
       "      <td>0.790379</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_test</th>\n",
       "      <td>0.968588</td>\n",
       "      <td>0.855851</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.128851</td>\n",
       "      <td>0.684912</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_train</th>\n",
       "      <td>0.772604</td>\n",
       "      <td>0.890391</td>\n",
       "      <td>0.107409</td>\n",
       "      <td>0.852689</td>\n",
       "      <td>0.190785</td>\n",
       "      <td>0.475913</td>\n",
       "      <td>0.766394</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_test</th>\n",
       "      <td>0.769366</td>\n",
       "      <td>0.856921</td>\n",
       "      <td>0.098917</td>\n",
       "      <td>0.781331</td>\n",
       "      <td>0.175603</td>\n",
       "      <td>0.481936</td>\n",
       "      <td>0.686508</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_of_blendings_train</th>\n",
       "      <td>0.968705</td>\n",
       "      <td>0.890886</td>\n",
       "      <td>0.546227</td>\n",
       "      <td>0.026774</td>\n",
       "      <td>0.051047</td>\n",
       "      <td>0.209327</td>\n",
       "      <td>0.767271</td>\n",
       "      <td>3.908178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_of_blendings_test</th>\n",
       "      <td>0.968405</td>\n",
       "      <td>0.857378</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>0.216647</td>\n",
       "      <td>0.687300</td>\n",
       "      <td>3.908178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_tuned_0_train</th>\n",
       "      <td>0.779456</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.113386</td>\n",
       "      <td>0.882094</td>\n",
       "      <td>0.200942</td>\n",
       "      <td>0.458677</td>\n",
       "      <td>0.798335</td>\n",
       "      <td>5.372485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_tuned_0_test</th>\n",
       "      <td>0.774518</td>\n",
       "      <td>0.859248</td>\n",
       "      <td>0.100991</td>\n",
       "      <td>0.781123</td>\n",
       "      <td>0.178858</td>\n",
       "      <td>0.467763</td>\n",
       "      <td>0.691879</td>\n",
       "      <td>5.372485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline_0_train</th>\n",
       "      <td>0.751777</td>\n",
       "      <td>0.866733</td>\n",
       "      <td>0.096302</td>\n",
       "      <td>0.822503</td>\n",
       "      <td>0.172417</td>\n",
       "      <td>0.501353</td>\n",
       "      <td>0.713617</td>\n",
       "      <td>1.973197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline_0_test</th>\n",
       "      <td>0.751385</td>\n",
       "      <td>0.849962</td>\n",
       "      <td>0.093039</td>\n",
       "      <td>0.789666</td>\n",
       "      <td>0.166465</td>\n",
       "      <td>0.503349</td>\n",
       "      <td>0.668484</td>\n",
       "      <td>1.973197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline+tuned_0_train</th>\n",
       "      <td>0.777784</td>\n",
       "      <td>0.901936</td>\n",
       "      <td>0.111903</td>\n",
       "      <td>0.874906</td>\n",
       "      <td>0.198427</td>\n",
       "      <td>0.461049</td>\n",
       "      <td>0.790888</td>\n",
       "      <td>4.991808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline+tuned_0_test</th>\n",
       "      <td>0.773201</td>\n",
       "      <td>0.859054</td>\n",
       "      <td>0.100704</td>\n",
       "      <td>0.783623</td>\n",
       "      <td>0.178473</td>\n",
       "      <td>0.469365</td>\n",
       "      <td>0.691422</td>\n",
       "      <td>4.991808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_sklearn_train</th>\n",
       "      <td>0.769534</td>\n",
       "      <td>0.905159</td>\n",
       "      <td>0.109784</td>\n",
       "      <td>0.890585</td>\n",
       "      <td>0.195471</td>\n",
       "      <td>0.479643</td>\n",
       "      <td>0.798137</td>\n",
       "      <td>5.336186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_sklearn_test</th>\n",
       "      <td>0.764669</td>\n",
       "      <td>0.859304</td>\n",
       "      <td>0.098184</td>\n",
       "      <td>0.792374</td>\n",
       "      <td>0.174718</td>\n",
       "      <td>0.488412</td>\n",
       "      <td>0.692107</td>\n",
       "      <td>5.336186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "model                                                                      \n",
       "Voting_weighted_auto_train       0.968692  0.894470   0.618962  0.010728   \n",
       "Voting_weighted_auto_test        0.968575  0.857126   0.514085  0.007605   \n",
       "Voting_weighted_train            0.968697  0.893210   0.606811  0.012154   \n",
       "Voting_weighted_test             0.968542  0.857288   0.482558  0.008647   \n",
       "Voting_no_weights_train          0.968654  0.902040   0.649682  0.006325   \n",
       "Voting_no_weights_test           0.968588  0.855851   0.550000  0.004584   \n",
       "Blending_train                   0.772604  0.890391   0.107409  0.852689   \n",
       "Blending_test                    0.769366  0.856921   0.098917  0.781331   \n",
       "Voting_of_blendings_train        0.968705  0.890886   0.546227  0.026774   \n",
       "Voting_of_blendings_test         0.968405  0.857378   0.444700  0.020106   \n",
       "Stacking_tuned_0_train           0.779456  0.905411   0.113386  0.882094   \n",
       "Stacking_tuned_0_test            0.774518  0.859248   0.100991  0.781123   \n",
       "Stacking_baseline_0_train        0.751777  0.866733   0.096302  0.822503   \n",
       "Stacking_baseline_0_test         0.751385  0.849962   0.093039  0.789666   \n",
       "Stacking_baseline+tuned_0_train  0.777784  0.901936   0.111903  0.874906   \n",
       "Stacking_baseline+tuned_0_test   0.773201  0.859054   0.100704  0.783623   \n",
       "Stacking_sklearn_train           0.769534  0.905159   0.109784  0.890585   \n",
       "Stacking_sklearn_test            0.764669  0.859304   0.098184  0.792374   \n",
       "\n",
       "                                       f1   Logloss  gini_stability  \\\n",
       "model                                                                 \n",
       "Voting_weighted_auto_train       0.021090  0.102074        0.773653   \n",
       "Voting_weighted_auto_test        0.014988  0.110082        0.688272   \n",
       "Voting_weighted_train            0.023831  0.109814        0.770778   \n",
       "Voting_weighted_test             0.016989  0.116794        0.689036   \n",
       "Voting_no_weights_train          0.012528  0.120357        0.790379   \n",
       "Voting_no_weights_test           0.009092  0.128851        0.684912   \n",
       "Blending_train                   0.190785  0.475913        0.766394   \n",
       "Blending_test                    0.175603  0.481936        0.686508   \n",
       "Voting_of_blendings_train        0.051047  0.209327        0.767271   \n",
       "Voting_of_blendings_test         0.038473  0.216647        0.687300   \n",
       "Stacking_tuned_0_train           0.200942  0.458677        0.798335   \n",
       "Stacking_tuned_0_test            0.178858  0.467763        0.691879   \n",
       "Stacking_baseline_0_train        0.172417  0.501353        0.713617   \n",
       "Stacking_baseline_0_test         0.166465  0.503349        0.668484   \n",
       "Stacking_baseline+tuned_0_train  0.198427  0.461049        0.790888   \n",
       "Stacking_baseline+tuned_0_test   0.178473  0.469365        0.691422   \n",
       "Stacking_sklearn_train           0.195471  0.479643        0.798137   \n",
       "Stacking_sklearn_test            0.174718  0.488412        0.692107   \n",
       "\n",
       "                                 overfitting, %  \n",
       "model                                            \n",
       "Voting_weighted_auto_train             4.356915  \n",
       "Voting_weighted_auto_test              4.356915  \n",
       "Voting_weighted_train                  4.190239  \n",
       "Voting_weighted_test                   4.190239  \n",
       "Voting_no_weights_train                5.396866  \n",
       "Voting_no_weights_test                 5.396866  \n",
       "Blending_train                         3.905935  \n",
       "Blending_test                          3.905935  \n",
       "Voting_of_blendings_train              3.908178  \n",
       "Voting_of_blendings_test               3.908178  \n",
       "Stacking_tuned_0_train                 5.372485  \n",
       "Stacking_tuned_0_test                  5.372485  \n",
       "Stacking_baseline_0_train              1.973197  \n",
       "Stacking_baseline_0_test               1.973197  \n",
       "Stacking_baseline+tuned_0_train        4.991808  \n",
       "Stacking_baseline+tuned_0_test         4.991808  \n",
       "Stacking_sklearn_train                 5.336186  \n",
       "Stacking_sklearn_test                  5.336186  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_ = metrics_estimation(\n",
    "    clf_sklearn,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    weeks_train,\n",
    "    weeks_test,\n",
    "    name=\"Stacking_sklearn\",\n",
    ")\n",
    "metrics = pd.concat([metrics, metrics_])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33617ce-1dac-4b27-a18a-d9cb9ff41f37",
   "metadata": {},
   "source": [
    "## StackingClassifier 4 random states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea4d1961-1432-48c9-a492-c5be74382369",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    (\"lgb_b\", clf_lgb_baseline),\n",
    "    (\"cat_b\", clf_catboost_baseline),\n",
    "    (\"xgb_b\", clf_xgb_baseline),\n",
    "]\n",
    "rnd_states = [0, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "066013c4-113a-4245-b1ba-5f41b9b6f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in rnd_states:\n",
    "    clf_catboost = CatBoostClassifier(\n",
    "        random_state=i,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        verbose=0,\n",
    "        **params[\"cat_boost\"],\n",
    "        **best_params[\"cat_boost\"]\n",
    "    )\n",
    "\n",
    "    clf_lgb = LGBMClassifier(\n",
    "        random_state=i,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        **params[\"lgbm\"],\n",
    "        **best_params[\"lgbm\"]\n",
    "    )\n",
    "\n",
    "    clf_xgb = XGBClassifier(\n",
    "        random_state=i,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        eval_metric=\"auc\",\n",
    "        verbose=0,\n",
    "        **params[\"xgb\"],\n",
    "        **best_params[\"xgb\"]\n",
    "    )\n",
    "    estimators.append((\"lgb_%s\" % i, clf_lgb))\n",
    "    estimators.append((\"cat_%s\" % i, clf_catboost))\n",
    "    estimators.append((\"xgb_%s\" % i, clf_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13f740e9-5377-40ec-b813-d8568faa8f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_estimator = LogisticRegression(class_weight=\"balanced\", random_state=0, n_jobs=24)\n",
    "clf = StackingClassifierCustom(\n",
    "    estimators, final_estimator, n_jobs=1, n_splits=5, random_states=rnd_states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa2bf8-a8f4-4f31-9f4b-0e6ecf0cd210",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, groups=weeks_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bb4fde7f-0965-420e-8ee9-cbdedc1b4e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>gini_stability</th>\n",
       "      <th>overfitting, %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_train</th>\n",
       "      <td>0.968692</td>\n",
       "      <td>0.894470</td>\n",
       "      <td>0.618962</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.102074</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_test</th>\n",
       "      <td>0.968575</td>\n",
       "      <td>0.857126</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.014988</td>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.688272</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_train</th>\n",
       "      <td>0.968697</td>\n",
       "      <td>0.893210</td>\n",
       "      <td>0.606811</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.109814</td>\n",
       "      <td>0.770778</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_test</th>\n",
       "      <td>0.968542</td>\n",
       "      <td>0.857288</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>0.116794</td>\n",
       "      <td>0.689036</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_train</th>\n",
       "      <td>0.968654</td>\n",
       "      <td>0.902040</td>\n",
       "      <td>0.649682</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.012528</td>\n",
       "      <td>0.120357</td>\n",
       "      <td>0.790379</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_test</th>\n",
       "      <td>0.968588</td>\n",
       "      <td>0.855851</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.128851</td>\n",
       "      <td>0.684912</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_train</th>\n",
       "      <td>0.772604</td>\n",
       "      <td>0.890391</td>\n",
       "      <td>0.107409</td>\n",
       "      <td>0.852689</td>\n",
       "      <td>0.190785</td>\n",
       "      <td>0.475913</td>\n",
       "      <td>0.766394</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_test</th>\n",
       "      <td>0.769366</td>\n",
       "      <td>0.856921</td>\n",
       "      <td>0.098917</td>\n",
       "      <td>0.781331</td>\n",
       "      <td>0.175603</td>\n",
       "      <td>0.481936</td>\n",
       "      <td>0.686508</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_of_blendings_train</th>\n",
       "      <td>0.968705</td>\n",
       "      <td>0.890886</td>\n",
       "      <td>0.546227</td>\n",
       "      <td>0.026774</td>\n",
       "      <td>0.051047</td>\n",
       "      <td>0.209327</td>\n",
       "      <td>0.767271</td>\n",
       "      <td>3.908178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_of_blendings_test</th>\n",
       "      <td>0.968405</td>\n",
       "      <td>0.857378</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>0.216647</td>\n",
       "      <td>0.687300</td>\n",
       "      <td>3.908178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_tuned_0_train</th>\n",
       "      <td>0.779456</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.113386</td>\n",
       "      <td>0.882094</td>\n",
       "      <td>0.200942</td>\n",
       "      <td>0.458677</td>\n",
       "      <td>0.798335</td>\n",
       "      <td>5.372485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_tuned_0_test</th>\n",
       "      <td>0.774518</td>\n",
       "      <td>0.859248</td>\n",
       "      <td>0.100991</td>\n",
       "      <td>0.781123</td>\n",
       "      <td>0.178858</td>\n",
       "      <td>0.467763</td>\n",
       "      <td>0.691879</td>\n",
       "      <td>5.372485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline_0_train</th>\n",
       "      <td>0.751777</td>\n",
       "      <td>0.866733</td>\n",
       "      <td>0.096302</td>\n",
       "      <td>0.822503</td>\n",
       "      <td>0.172417</td>\n",
       "      <td>0.501353</td>\n",
       "      <td>0.713617</td>\n",
       "      <td>1.973197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline_0_test</th>\n",
       "      <td>0.751385</td>\n",
       "      <td>0.849962</td>\n",
       "      <td>0.093039</td>\n",
       "      <td>0.789666</td>\n",
       "      <td>0.166465</td>\n",
       "      <td>0.503349</td>\n",
       "      <td>0.668484</td>\n",
       "      <td>1.973197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline+tuned_0_train</th>\n",
       "      <td>0.777784</td>\n",
       "      <td>0.901936</td>\n",
       "      <td>0.111903</td>\n",
       "      <td>0.874906</td>\n",
       "      <td>0.198427</td>\n",
       "      <td>0.461049</td>\n",
       "      <td>0.790888</td>\n",
       "      <td>4.991808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline+tuned_0_test</th>\n",
       "      <td>0.773201</td>\n",
       "      <td>0.859054</td>\n",
       "      <td>0.100704</td>\n",
       "      <td>0.783623</td>\n",
       "      <td>0.178473</td>\n",
       "      <td>0.469365</td>\n",
       "      <td>0.691422</td>\n",
       "      <td>4.991808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_sklearn_train</th>\n",
       "      <td>0.769534</td>\n",
       "      <td>0.905159</td>\n",
       "      <td>0.109784</td>\n",
       "      <td>0.890585</td>\n",
       "      <td>0.195471</td>\n",
       "      <td>0.479643</td>\n",
       "      <td>0.798137</td>\n",
       "      <td>5.336186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_sklearn_test</th>\n",
       "      <td>0.764669</td>\n",
       "      <td>0.859304</td>\n",
       "      <td>0.098184</td>\n",
       "      <td>0.792374</td>\n",
       "      <td>0.174718</td>\n",
       "      <td>0.488412</td>\n",
       "      <td>0.692107</td>\n",
       "      <td>5.336186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_4_rnd_states_train</th>\n",
       "      <td>0.779366</td>\n",
       "      <td>0.904164</td>\n",
       "      <td>0.112935</td>\n",
       "      <td>0.877979</td>\n",
       "      <td>0.200127</td>\n",
       "      <td>0.458271</td>\n",
       "      <td>0.795598</td>\n",
       "      <td>5.206108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_4_rnd_states_test</th>\n",
       "      <td>0.774789</td>\n",
       "      <td>0.859422</td>\n",
       "      <td>0.101233</td>\n",
       "      <td>0.782373</td>\n",
       "      <td>0.179271</td>\n",
       "      <td>0.467085</td>\n",
       "      <td>0.692689</td>\n",
       "      <td>5.206108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "model                                                                      \n",
       "Voting_weighted_auto_train       0.968692  0.894470   0.618962  0.010728   \n",
       "Voting_weighted_auto_test        0.968575  0.857126   0.514085  0.007605   \n",
       "Voting_weighted_train            0.968697  0.893210   0.606811  0.012154   \n",
       "Voting_weighted_test             0.968542  0.857288   0.482558  0.008647   \n",
       "Voting_no_weights_train          0.968654  0.902040   0.649682  0.006325   \n",
       "Voting_no_weights_test           0.968588  0.855851   0.550000  0.004584   \n",
       "Blending_train                   0.772604  0.890391   0.107409  0.852689   \n",
       "Blending_test                    0.769366  0.856921   0.098917  0.781331   \n",
       "Voting_of_blendings_train        0.968705  0.890886   0.546227  0.026774   \n",
       "Voting_of_blendings_test         0.968405  0.857378   0.444700  0.020106   \n",
       "Stacking_tuned_0_train           0.779456  0.905411   0.113386  0.882094   \n",
       "Stacking_tuned_0_test            0.774518  0.859248   0.100991  0.781123   \n",
       "Stacking_baseline_0_train        0.751777  0.866733   0.096302  0.822503   \n",
       "Stacking_baseline_0_test         0.751385  0.849962   0.093039  0.789666   \n",
       "Stacking_baseline+tuned_0_train  0.777784  0.901936   0.111903  0.874906   \n",
       "Stacking_baseline+tuned_0_test   0.773201  0.859054   0.100704  0.783623   \n",
       "Stacking_sklearn_train           0.769534  0.905159   0.109784  0.890585   \n",
       "Stacking_sklearn_test            0.764669  0.859304   0.098184  0.792374   \n",
       "Stacking_4_rnd_states_train      0.779366  0.904164   0.112935  0.877979   \n",
       "Stacking_4_rnd_states_test       0.774789  0.859422   0.101233  0.782373   \n",
       "\n",
       "                                       f1   Logloss  gini_stability  \\\n",
       "model                                                                 \n",
       "Voting_weighted_auto_train       0.021090  0.102074        0.773653   \n",
       "Voting_weighted_auto_test        0.014988  0.110082        0.688272   \n",
       "Voting_weighted_train            0.023831  0.109814        0.770778   \n",
       "Voting_weighted_test             0.016989  0.116794        0.689036   \n",
       "Voting_no_weights_train          0.012528  0.120357        0.790379   \n",
       "Voting_no_weights_test           0.009092  0.128851        0.684912   \n",
       "Blending_train                   0.190785  0.475913        0.766394   \n",
       "Blending_test                    0.175603  0.481936        0.686508   \n",
       "Voting_of_blendings_train        0.051047  0.209327        0.767271   \n",
       "Voting_of_blendings_test         0.038473  0.216647        0.687300   \n",
       "Stacking_tuned_0_train           0.200942  0.458677        0.798335   \n",
       "Stacking_tuned_0_test            0.178858  0.467763        0.691879   \n",
       "Stacking_baseline_0_train        0.172417  0.501353        0.713617   \n",
       "Stacking_baseline_0_test         0.166465  0.503349        0.668484   \n",
       "Stacking_baseline+tuned_0_train  0.198427  0.461049        0.790888   \n",
       "Stacking_baseline+tuned_0_test   0.178473  0.469365        0.691422   \n",
       "Stacking_sklearn_train           0.195471  0.479643        0.798137   \n",
       "Stacking_sklearn_test            0.174718  0.488412        0.692107   \n",
       "Stacking_4_rnd_states_train      0.200127  0.458271        0.795598   \n",
       "Stacking_4_rnd_states_test       0.179271  0.467085        0.692689   \n",
       "\n",
       "                                 overfitting, %  \n",
       "model                                            \n",
       "Voting_weighted_auto_train             4.356915  \n",
       "Voting_weighted_auto_test              4.356915  \n",
       "Voting_weighted_train                  4.190239  \n",
       "Voting_weighted_test                   4.190239  \n",
       "Voting_no_weights_train                5.396866  \n",
       "Voting_no_weights_test                 5.396866  \n",
       "Blending_train                         3.905935  \n",
       "Blending_test                          3.905935  \n",
       "Voting_of_blendings_train              3.908178  \n",
       "Voting_of_blendings_test               3.908178  \n",
       "Stacking_tuned_0_train                 5.372485  \n",
       "Stacking_tuned_0_test                  5.372485  \n",
       "Stacking_baseline_0_train              1.973197  \n",
       "Stacking_baseline_0_test               1.973197  \n",
       "Stacking_baseline+tuned_0_train        4.991808  \n",
       "Stacking_baseline+tuned_0_test         4.991808  \n",
       "Stacking_sklearn_train                 5.336186  \n",
       "Stacking_sklearn_test                  5.336186  \n",
       "Stacking_4_rnd_states_train            5.206108  \n",
       "Stacking_4_rnd_states_test             5.206108  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_ = metrics_estimation(\n",
    "    clf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    weeks_train,\n",
    "    weeks_test,\n",
    "    name=\"Stacking_4_rnd_states\",\n",
    ")\n",
    "metrics = pd.concat([metrics, metrics_])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6530c53-c4fc-438b-bf62-83605dbde53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"best_model.bin\", \"wb\") as fout:\n",
    "    dill.dump(clf, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8db4c8e7-996b-44ae-954c-87e97fa1134d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>gini_stability</th>\n",
       "      <th>overfitting, %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_auto_test</th>\n",
       "      <td>0.968575</td>\n",
       "      <td>0.857126</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.014988</td>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.688272</td>\n",
       "      <td>4.356915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_weighted_test</th>\n",
       "      <td>0.968542</td>\n",
       "      <td>0.857288</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>0.116794</td>\n",
       "      <td>0.689036</td>\n",
       "      <td>4.190239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_no_weights_test</th>\n",
       "      <td>0.968588</td>\n",
       "      <td>0.855851</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.128851</td>\n",
       "      <td>0.684912</td>\n",
       "      <td>5.396866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending_test</th>\n",
       "      <td>0.769366</td>\n",
       "      <td>0.856921</td>\n",
       "      <td>0.098917</td>\n",
       "      <td>0.781331</td>\n",
       "      <td>0.175603</td>\n",
       "      <td>0.481936</td>\n",
       "      <td>0.686508</td>\n",
       "      <td>3.905935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_of_blendings_test</th>\n",
       "      <td>0.968405</td>\n",
       "      <td>0.857378</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>0.216647</td>\n",
       "      <td>0.687300</td>\n",
       "      <td>3.908178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_tuned_0_test</th>\n",
       "      <td>0.774518</td>\n",
       "      <td>0.859248</td>\n",
       "      <td>0.100991</td>\n",
       "      <td>0.781123</td>\n",
       "      <td>0.178858</td>\n",
       "      <td>0.467763</td>\n",
       "      <td>0.691879</td>\n",
       "      <td>5.372485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline_0_test</th>\n",
       "      <td>0.751385</td>\n",
       "      <td>0.849962</td>\n",
       "      <td>0.093039</td>\n",
       "      <td>0.789666</td>\n",
       "      <td>0.166465</td>\n",
       "      <td>0.503349</td>\n",
       "      <td>0.668484</td>\n",
       "      <td>1.973197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_baseline+tuned_0_test</th>\n",
       "      <td>0.773201</td>\n",
       "      <td>0.859054</td>\n",
       "      <td>0.100704</td>\n",
       "      <td>0.783623</td>\n",
       "      <td>0.178473</td>\n",
       "      <td>0.469365</td>\n",
       "      <td>0.691422</td>\n",
       "      <td>4.991808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_sklearn_test</th>\n",
       "      <td>0.764669</td>\n",
       "      <td>0.859304</td>\n",
       "      <td>0.098184</td>\n",
       "      <td>0.792374</td>\n",
       "      <td>0.174718</td>\n",
       "      <td>0.488412</td>\n",
       "      <td>0.692107</td>\n",
       "      <td>5.336186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_4_rnd_states_test</th>\n",
       "      <td>0.774789</td>\n",
       "      <td>0.859422</td>\n",
       "      <td>0.101233</td>\n",
       "      <td>0.782373</td>\n",
       "      <td>0.179271</td>\n",
       "      <td>0.467085</td>\n",
       "      <td>0.692689</td>\n",
       "      <td>5.206108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "model                                                                     \n",
       "Voting_weighted_auto_test       0.968575  0.857126   0.514085  0.007605   \n",
       "Voting_weighted_test            0.968542  0.857288   0.482558  0.008647   \n",
       "Voting_no_weights_test          0.968588  0.855851   0.550000  0.004584   \n",
       "Blending_test                   0.769366  0.856921   0.098917  0.781331   \n",
       "Voting_of_blendings_test        0.968405  0.857378   0.444700  0.020106   \n",
       "Stacking_tuned_0_test           0.774518  0.859248   0.100991  0.781123   \n",
       "Stacking_baseline_0_test        0.751385  0.849962   0.093039  0.789666   \n",
       "Stacking_baseline+tuned_0_test  0.773201  0.859054   0.100704  0.783623   \n",
       "Stacking_sklearn_test           0.764669  0.859304   0.098184  0.792374   \n",
       "Stacking_4_rnd_states_test      0.774789  0.859422   0.101233  0.782373   \n",
       "\n",
       "                                      f1   Logloss  gini_stability  \\\n",
       "model                                                                \n",
       "Voting_weighted_auto_test       0.014988  0.110082        0.688272   \n",
       "Voting_weighted_test            0.016989  0.116794        0.689036   \n",
       "Voting_no_weights_test          0.009092  0.128851        0.684912   \n",
       "Blending_test                   0.175603  0.481936        0.686508   \n",
       "Voting_of_blendings_test        0.038473  0.216647        0.687300   \n",
       "Stacking_tuned_0_test           0.178858  0.467763        0.691879   \n",
       "Stacking_baseline_0_test        0.166465  0.503349        0.668484   \n",
       "Stacking_baseline+tuned_0_test  0.178473  0.469365        0.691422   \n",
       "Stacking_sklearn_test           0.174718  0.488412        0.692107   \n",
       "Stacking_4_rnd_states_test      0.179271  0.467085        0.692689   \n",
       "\n",
       "                                overfitting, %  \n",
       "model                                           \n",
       "Voting_weighted_auto_test             4.356915  \n",
       "Voting_weighted_test                  4.190239  \n",
       "Voting_no_weights_test                5.396866  \n",
       "Blending_test                         3.905935  \n",
       "Voting_of_blendings_test              3.908178  \n",
       "Stacking_tuned_0_test                 5.372485  \n",
       "Stacking_baseline_0_test              1.973197  \n",
       "Stacking_baseline+tuned_0_test        4.991808  \n",
       "Stacking_sklearn_test                 5.336186  \n",
       "Stacking_4_rnd_states_test            5.206108  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.iloc[1::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b317edc2-4d36-4c4c-a380-cfecb353b9b9",
   "metadata": {},
   "source": [
    "Stacking показал результаты лучше чем Voting и Blending. Причем реализация от sklearn дает хорошие результаты. Лучше нее оказался stacking на основе 15 моделей. Возможно получить еще лучше результаты если добавить еще вариаций random_state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83524b52-55d4-4bef-b61f-9c0d7dee8d04",
   "metadata": {},
   "source": [
    "# Калибровка лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9faf0954-c06e-4277-85b7-5d731ad3b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "clb_clf = CalibratedClassifierCV(clf, method=\"isotonic\", cv=\"prefit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f70827c6-68c4-441f-9e15-9d5a84da5a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CalibratedClassifierCV(cv=&#x27;prefit&#x27;,\n",
       "                       estimator=StackingClassifierCustom(estimators=[(&#x27;lgb_b&#x27;,\n",
       "                                                                       LGBMClassifier(n_jobs=24,\n",
       "                                                                                      random_state=0,\n",
       "                                                                                      scale_pos_weight=30.8093141510604,\n",
       "                                                                                      verbose=-1)),\n",
       "                                                                      (&#x27;cat_b&#x27;,\n",
       "                                                                       &lt;catboost.core.CatBoostClassifier object at 0x0000023E95E3C2B0&gt;),\n",
       "                                                                      (&#x27;xgb_b&#x27;,\n",
       "                                                                       XGBClassifier(base_score=None,\n",
       "                                                                                     booster=None,\n",
       "                                                                                     callbacks=None,\n",
       "                                                                                     colsample_bylevel=None,\n",
       "                                                                                     colsample_b...\n",
       "                                                                                     max_cat_to_onehot=None,\n",
       "                                                                                     max_delta_step=None,\n",
       "                                                                                     max_depth=6,\n",
       "                                                                                     max_leaves=None,\n",
       "                                                                                     min_child_weight=5,\n",
       "                                                                                     missing=nan,\n",
       "                                                                                     monotone_constraints=None,\n",
       "                                                                                     multi_strategy=None,\n",
       "                                                                                     n_estimators=2000,\n",
       "                                                                                     n_jobs=None,\n",
       "                                                                                     num_parallel_tree=None,\n",
       "                                                                                     random_state=1000, ...))],\n",
       "                                                          final_estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                                                             n_jobs=24,\n",
       "                                                                                             random_state=0),\n",
       "                                                          n_jobs=1,\n",
       "                                                          random_states=[0, 10,\n",
       "                                                                         100,\n",
       "                                                                         1000]),\n",
       "                       method=&#x27;isotonic&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CalibratedClassifierCV</label><div class=\"sk-toggleable__content\"><pre>CalibratedClassifierCV(cv=&#x27;prefit&#x27;,\n",
       "                       estimator=StackingClassifierCustom(estimators=[(&#x27;lgb_b&#x27;,\n",
       "                                                                       LGBMClassifier(n_jobs=24,\n",
       "                                                                                      random_state=0,\n",
       "                                                                                      scale_pos_weight=30.8093141510604,\n",
       "                                                                                      verbose=-1)),\n",
       "                                                                      (&#x27;cat_b&#x27;,\n",
       "                                                                       &lt;catboost.core.CatBoostClassifier object at 0x0000023E95E3C2B0&gt;),\n",
       "                                                                      (&#x27;xgb_b&#x27;,\n",
       "                                                                       XGBClassifier(base_score=None,\n",
       "                                                                                     booster=None,\n",
       "                                                                                     callbacks=None,\n",
       "                                                                                     colsample_bylevel=None,\n",
       "                                                                                     colsample_b...\n",
       "                                                                                     max_cat_to_onehot=None,\n",
       "                                                                                     max_delta_step=None,\n",
       "                                                                                     max_depth=6,\n",
       "                                                                                     max_leaves=None,\n",
       "                                                                                     min_child_weight=5,\n",
       "                                                                                     missing=nan,\n",
       "                                                                                     monotone_constraints=None,\n",
       "                                                                                     multi_strategy=None,\n",
       "                                                                                     n_estimators=2000,\n",
       "                                                                                     n_jobs=None,\n",
       "                                                                                     num_parallel_tree=None,\n",
       "                                                                                     random_state=1000, ...))],\n",
       "                                                          final_estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                                                             n_jobs=24,\n",
       "                                                                                             random_state=0),\n",
       "                                                          n_jobs=1,\n",
       "                                                          random_states=[0, 10,\n",
       "                                                                         100,\n",
       "                                                                         1000]),\n",
       "                       method=&#x27;isotonic&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: StackingClassifierCustom</label><div class=\"sk-toggleable__content\"><pre>StackingClassifierCustom(estimators=[(&#x27;lgb_b&#x27;,\n",
       "                                      LGBMClassifier(n_jobs=24, random_state=0,\n",
       "                                                     scale_pos_weight=30.8093141510604,\n",
       "                                                     verbose=-1)),\n",
       "                                     (&#x27;cat_b&#x27;,\n",
       "                                      &lt;catboost.core.CatBoostClassifier object at 0x0000023E95E3C2B0&gt;),\n",
       "                                     (&#x27;xgb_b&#x27;,\n",
       "                                      XGBClassifier(base_score=None,\n",
       "                                                    booster=None,\n",
       "                                                    callbacks=None,\n",
       "                                                    colsample_bylevel=None,\n",
       "                                                    colsample_bynode=None,\n",
       "                                                    colsample_bytree=None,\n",
       "                                                    device=&#x27;cuda...\n",
       "                                                    max_cat_to_onehot=None,\n",
       "                                                    max_delta_step=None,\n",
       "                                                    max_depth=6,\n",
       "                                                    max_leaves=None,\n",
       "                                                    min_child_weight=5,\n",
       "                                                    missing=nan,\n",
       "                                                    monotone_constraints=None,\n",
       "                                                    multi_strategy=None,\n",
       "                                                    n_estimators=2000,\n",
       "                                                    n_jobs=None,\n",
       "                                                    num_parallel_tree=None,\n",
       "                                                    random_state=1000, ...))],\n",
       "                         final_estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                            n_jobs=24,\n",
       "                                                            random_state=0),\n",
       "                         n_jobs=1, random_states=[0, 10, 100, 1000])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">final_estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, n_jobs=24, random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, n_jobs=24, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "CalibratedClassifierCV(cv='prefit',\n",
       "                       estimator=StackingClassifierCustom(estimators=[('lgb_b',\n",
       "                                                                       LGBMClassifier(n_jobs=24,\n",
       "                                                                                      random_state=0,\n",
       "                                                                                      scale_pos_weight=30.8093141510604,\n",
       "                                                                                      verbose=-1)),\n",
       "                                                                      ('cat_b',\n",
       "                                                                       <catboost.core.CatBoostClassifier object at 0x0000023E95E3C2B0>),\n",
       "                                                                      ('xgb_b',\n",
       "                                                                       XGBClassifier(base_score=None,\n",
       "                                                                                     booster=None,\n",
       "                                                                                     callbacks=None,\n",
       "                                                                                     colsample_bylevel=None,\n",
       "                                                                                     colsample_b...\n",
       "                                                                                     max_cat_to_onehot=None,\n",
       "                                                                                     max_delta_step=None,\n",
       "                                                                                     max_depth=6,\n",
       "                                                                                     max_leaves=None,\n",
       "                                                                                     min_child_weight=5,\n",
       "                                                                                     missing=nan,\n",
       "                                                                                     monotone_constraints=None,\n",
       "                                                                                     multi_strategy=None,\n",
       "                                                                                     n_estimators=2000,\n",
       "                                                                                     n_jobs=None,\n",
       "                                                                                     num_parallel_tree=None,\n",
       "                                                                                     random_state=1000, ...))],\n",
       "                                                          final_estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                                                             n_jobs=24,\n",
       "                                                                                             random_state=0),\n",
       "                                                          n_jobs=1,\n",
       "                                                          random_states=[0, 10,\n",
       "                                                                         100,\n",
       "                                                                         1000]),\n",
       "                       method='isotonic')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clb_clf.fit(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01233b13-b476-4a41-945c-c1d33f7346e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"best_model_calib.bin\", \"wb\") as fout:\n",
    "    dill.dump(clb_clf, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "55206544-f572-45cd-85bf-328795665e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Calibration plots')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_list = [(\"Stacking\", clf), (\"Calibrated Stacking\", clb_clf)]\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "gs = GridSpec(4, 2)\n",
    "colors = plt.get_cmap(\"Dark2\")\n",
    "\n",
    "ax_calibration_curve = fig.add_subplot(gs[:2, :2])\n",
    "calibration_displays = {}\n",
    "for i, (name, clf_) in enumerate(clf_list):\n",
    "    y_prob = clf_.predict_proba(X_train_)[:, 1]\n",
    "    display = CalibrationDisplay.from_predictions(\n",
    "        y_train_,\n",
    "        y_prob,\n",
    "        n_bins=20,\n",
    "        name=name,\n",
    "        ax=ax_calibration_curve,\n",
    "        color=colors(i),\n",
    "    )\n",
    "    calibration_displays[name] = display\n",
    "\n",
    "ax_calibration_curve.grid()\n",
    "ax_calibration_curve.set_title(\"Calibration plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dd984fb-03f2-417a-a2a5-a8dfa862caf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>gini_stability</th>\n",
       "      <th>overfitting, %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stacking_calibrated_train</th>\n",
       "      <td>0.968933</td>\n",
       "      <td>0.904080</td>\n",
       "      <td>0.624040</td>\n",
       "      <td>0.029613</td>\n",
       "      <td>0.056543</td>\n",
       "      <td>0.098579</td>\n",
       "      <td>0.795425</td>\n",
       "      <td>5.238701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_calibrated_test</th>\n",
       "      <td>0.968539</td>\n",
       "      <td>0.859075</td>\n",
       "      <td>0.491184</td>\n",
       "      <td>0.020315</td>\n",
       "      <td>0.039016</td>\n",
       "      <td>0.114749</td>\n",
       "      <td>0.691429</td>\n",
       "      <td>5.238701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy   ROC_AUC  Precision    Recall        f1  \\\n",
       "model                                                                          \n",
       "Stacking_calibrated_train  0.968933  0.904080   0.624040  0.029613  0.056543   \n",
       "Stacking_calibrated_test   0.968539  0.859075   0.491184  0.020315  0.039016   \n",
       "\n",
       "                            Logloss  gini_stability  overfitting, %  \n",
       "model                                                                \n",
       "Stacking_calibrated_train  0.098579        0.795425        5.238701  \n",
       "Stacking_calibrated_test   0.114749        0.691429        5.238701  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_estimation(\n",
    "    clb_clf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    weeks_train,\n",
    "    weeks_test,\n",
    "    name=\"Stacking_calibrated\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9ed950-986c-4798-93a4-7f5541ee5332",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dea275a-f121-4ad5-bef7-4152825f02ab",
   "metadata": {},
   "source": [
    "Составлены ансамблевые модели Voting, Blending, Stacking классификаторов. По сравнению с одиночными моделями Stacking позволяет улучшить метрику ROC_AUC на 0.2156, а gini_stability на 0.3072, что можно назвать хорошим результатом."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec8b1e-44f5-409a-9174-06e8082f8472",
   "metadata": {},
   "source": [
    "В качестве лучшей полученной модели возьмем Stacking_4_rnd_states. Модель получена с помощью класса StackingClassifierCustom с 3 baseline моделями и 12 CatBoost, LightGBM, XGBoost моделями с лучшими гиперпараметрами с разными random_state. Эта модель позволяет получить в результате значения метрик ROC_AUC (0.859422), F1_score (0.179271) и gini_stability (0.692689) выше остальных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80cc80e-5eec-44a1-8d4a-e4238e4757ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
